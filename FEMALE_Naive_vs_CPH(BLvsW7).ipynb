{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8a2d530-3ec9-42fd-be5f-e5efd35b0fa7",
   "metadata": {},
   "source": [
    "# Female Naive Vs Female CPH\n",
    "1. Female CPH (baseline)\n",
    "2. Female CPH (Week 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "106ffb1b-7a21-4433-b76f-276108f014de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"C:\\\\Users\\\\\"+os.getlogin()+\"\\\\OneDrive - Instituto Tecnologico y de Estudios Superiores de Monterrey\\\\PainClassifier\")\n",
    "from my_data_generator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "748e72bd-7f6a-4a51-9d62-8c9891680af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import os\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "import warnings\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support as score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from datetime import datetime\n",
    "import scipy as sp\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Conv3D, MaxPooling3D, Flatten, Dropout, GlobalAveragePooling3D, concatenate, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from keras.regularizers import l2\n",
    "import cv2\n",
    "from keras import initializers\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import BatchNormalization\n",
    "import tensorflow as tf\n",
    "from keras import losses\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import wandb\n",
    "from wandb.integration.keras import WandbCallback\n",
    "import gc\n",
    "#from numba import cuda\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43ca2d53-8010-4075-a5e1-55782abcec4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Devices:\", tf.config.list_physical_devices())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25446ae9-81d1-4ee5-a514-bd2439a09094",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f00cc49e-1a2f-4bc1-a9d0-f96b762bb778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG16_3D(blocks):\n",
    "        \n",
    "    inputs = Input(shape=(42, 65, 29), name='input_layer')\n",
    "    x = Reshape(target_shape=[42, 65, 29, 1], name='input_x_3d_volumes')(inputs)\n",
    "\n",
    "    if blocks == 1:\n",
    "        print(\"entra al 1\")\n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 1st Conv Block\n",
    "        x = Conv3D(filters =64, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = Conv3D(filters =64, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.GlobalAveragePooling3D()(x)\n",
    "        x = tf.keras.layers.Dropout(0.5)(x)\n",
    "        \n",
    "    elif blocks == 2:\n",
    "        print(\"entra al 2\")\n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 1st Conv Block\n",
    "        x = Conv3D(filters =64, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = Conv3D(filters =64, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "            \n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 2nd Conv Block\n",
    "        x = Conv3D (filters =128, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = Conv3D (filters =128, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.GlobalAveragePooling3D()(x)\n",
    "        x = tf.keras.layers.Dropout(0.5)(x)\n",
    "        \n",
    "    elif blocks == 3:\n",
    "        print(\"entra al 3\")\n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 1st Conv Block\n",
    "        x = Conv3D(filters =64, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = Conv3D(filters =64, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "            \n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 2nd Conv Block\n",
    "        x = Conv3D (filters =128, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = Conv3D (filters =128, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "        \n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 3rd Conv block  \n",
    "        x = Conv3D (filters =256, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x) \n",
    "        x = Conv3D (filters =256, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x) \n",
    "        x = Conv3D (filters =256, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x) \n",
    "        x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.GlobalAveragePooling3D()(x)\n",
    "        x = tf.keras.layers.Dropout(0.5)(x)\n",
    "        \n",
    "    elif blocks == 4:\n",
    "        print(\"entra al 4\")\n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 1st Conv Block\n",
    "        x = Conv3D(filters =64, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = Conv3D(filters =64, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "            \n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 2nd Conv Block\n",
    "        x = Conv3D (filters =128, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = Conv3D (filters =128, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        #x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "        \n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 3rd Conv block  \n",
    "        x = Conv3D (filters =256, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x) \n",
    "        x = Conv3D (filters =256, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x) \n",
    "        x = Conv3D (filters =256, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x) \n",
    "        #x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "        \n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 4th Conv block\n",
    "        x = Conv3D (filters =512, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = Conv3D (filters =512, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = Conv3D (filters =512, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        #x = tf.keras.layers.GlobalAveragePooling3D()(x)\n",
    "        x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "    elif blocks == 5:\n",
    "        print(\"entra al 5\")\n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 1st Conv Block\n",
    "        x = Conv3D(filters =64, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.05))(x)\n",
    "        x = Conv3D(filters =64, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.05))(x)\n",
    "        #x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "            \n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 2nd Conv Block\n",
    "        x = Conv3D (filters =128, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.05))(x)\n",
    "        x = Conv3D (filters =128, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.05))(x)\n",
    "        #x = MaxPooling3D(pool_size =2, strides =1, padding ='same')(x)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "        \n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 3rd Conv block  \n",
    "        x = Conv3D (filters =256, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.05))(x) \n",
    "        x = Conv3D (filters =256, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.05))(x) \n",
    "        x = Conv3D (filters =256, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.05))(x) \n",
    "        #x = MaxPooling3D(pool_size =2, strides =1, padding ='same')(x)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "        \n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 4th Conv block\n",
    "        x = Conv3D (filters =512, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.05))(x)\n",
    "        x = Conv3D (filters =512, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.05))(x)\n",
    "        x = Conv3D (filters =512, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.05))(x)\n",
    "        #x = MaxPooling3D(pool_size =2, strides =1, padding ='same')(x)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 5th Conv block\n",
    "        x = Conv3D (filters =512, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.05))(x)\n",
    "        x = Conv3D (filters =512, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.05))(x)\n",
    "        x = Conv3D (filters =512, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.05))(x)\n",
    "        #x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.GlobalAveragePooling3D()(x)\n",
    "        x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    \n",
    "    # Fully connected layers  \n",
    "    x = Flatten()(x) \n",
    "    x = Dense(units = 4096, activation ='relu',kernel_regularizer='l2')(x)\n",
    "    #x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = Dense(units = 4096, activation ='relu',kernel_regularizer='l2')(x) \n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    output = Dense(units = 2,activation ='sigmoid',kernel_regularizer='l2')(x)\n",
    "    \n",
    "    # creating the model\n",
    "    VGG_3d_model = Model (inputs=inputs, outputs =output)\n",
    "    #model.summary()\n",
    "\n",
    "    return VGG_3d_model\n",
    "\n",
    "def set_pretrained_weigths(VGG_3d_model):\n",
    "    #VGG 16 with weights from Imagenet\n",
    "    pretrained_model = tf.keras.applications.VGG16(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        pooling='avg',\n",
    "        input_shape = (42, 65, 3)\n",
    "    )\n",
    "    \n",
    "    #conv layers on VGG_3d_model\n",
    "    layers_conv = []\n",
    "    for j in range(len(VGG_3d_model.layers)):\n",
    "        if \"conv3d\" in str(VGG_3d_model.layers[j]):\n",
    "            layers_conv.append(j)\n",
    "    layers_conv_pretrained = []\n",
    "    for j in range(len(pretrained_model.layers)):\n",
    "        if \"Conv2D\" in str(pretrained_model.layers[j]):\n",
    "            layers_conv_pretrained.append(j)\n",
    "    \n",
    "    for i in range(len(layers_conv)):\n",
    "        if \"Conv2D\" in str(pretrained_model.layers[layers_conv_pretrained[i]]):\n",
    "            if i == 0:\n",
    "                w = pretrained_model.layers[layers_conv_pretrained[i]].get_weights()[0].sum(axis=2, keepdims=True)\n",
    "            else:\n",
    "                w = pretrained_model.layers[layers_conv_pretrained[i]].get_weights()[0]\n",
    "                \n",
    "            w3d=[]\n",
    "            \n",
    "            w = np.reshape(w,(3,3,-1),order='F')\n",
    "            for j in range(len(w[0,0,:])):\n",
    "                for k in range(3):\n",
    "                    w3d.append(w[:,:,j])\n",
    "            w3d = np.transpose(w3d, (1,2,0))\n",
    "            \n",
    "            new_weights = np.reshape(w3d, np.array(VGG_3d_model.layers[layers_conv[i]].get_weights()[0]).shape,order='F')\n",
    "            new_bias = pretrained_model.layers[layers_conv_pretrained[i]].get_weights()[1]\n",
    "            \n",
    "            WnB = []\n",
    "            WnB.append(new_weights)\n",
    "            WnB.append(new_bias)\n",
    "    \n",
    "            VGG_3d_model.layers[layers_conv[i]].set_weights(WnB)\n",
    "\n",
    "    del pretrained_model, w, WnB, new_weights, new_bias, w3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b73eef-388d-4077-81f8-6eb93c39f318",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "732562b4-13a5-447d-8802-6be04933fcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionmatrix_multiclass(y_test,pred):\n",
    "    cm = confusion_matrix(y_test, (np.rint(preds)).astype(int) )\n",
    "    group_names = ['True baseline','False Baseline','False Baseline',   \n",
    "                   'False week 1','Truec','False Week 1',\n",
    "                  'False week 7','False week 7','True week 7']\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                    cm.flatten()]\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                         np.ndarray.flatten(cm/(np.sum(cm,axis=1).reshape(3,1)))]\n",
    "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "              zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(3,3)\n",
    "    sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', xticklabels = ['Baseline','Week 1','Week 7'] ,yticklabels = ['Baseline','Week 1','Week 7'])\n",
    "    plt.show()\n",
    "\n",
    "def confusionmatrix(y_test,preds):\n",
    "    #Construct the Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    group_names = ['True Naive','False Naive','False CPH','True CPH']\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                    cm.flatten()]\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                         np.ndarray.flatten(cm/(np.sum(cm,axis=1).reshape(2,1)))]\n",
    "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "              zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', xticklabels = ['MALE','FEMALE'] ,yticklabels = ['MALE','FEMALE'])\n",
    "    plt.show()\n",
    "    return sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', xticklabels = ['MALE','FEMALE'] ,yticklabels = ['MALE','FEMALE'])\n",
    "    \n",
    "def confusionmatrix_binary(y_test, preds):\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    group_names = ['True baseline','False baseline','False Week 1','True Week 1']\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                    cm.flatten()]\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                         np.ndarray.flatten(cm/(np.sum(cm,axis=1).reshape(2,1)))]\n",
    "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "              zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', xticklabels = ['MALE','FEMALE'] ,yticklabels = ['MALE','FEMALE'])\n",
    "    plt.show()\n",
    "\n",
    "def ROC(probs,y_test): #binary\n",
    "    #Classification Area under curve\n",
    "     warnings.filterwarnings('ignore')\n",
    "             \n",
    "     auc = roc_auc_score(y_test, probs)\n",
    "     print('AUC - Test Set: %.2f%%' % (auc*100))\n",
    "    \n",
    "     # calculate roc curve\n",
    "     fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "     # plot no skill\n",
    "     plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "     # plot the roc curve for the model\n",
    "     plt.plot(fpr, tpr, marker='.')\n",
    "     plt.xlabel('False positive rate')\n",
    "     plt.ylabel('Sensitivity/ Recall')\n",
    "     # show the plot\n",
    "     plt.show()\n",
    "    \n",
    "     probs = (np.rint(probs)).astype(int)   \n",
    "        \n",
    "     precision = precision_score(y_test, probs)\n",
    "     print('Precision: %f' % precision)\n",
    "     # recall: tp / (tp + fn)\n",
    "     recall = recall_score(y_test, probs)\n",
    "     print('Recall: %f' % recall)\n",
    "     # f1: tp / (tp + fp + fn)\n",
    "     f1 = f1_score(y_test, probs)\n",
    "     print('F1 score: %f' % f1)\n",
    "        \n",
    "def ROC_multiclass(model, y_test, n_class):\n",
    "    #y_test: array size (# of subjects, ) with classes \n",
    "    #pretrained model to be evaluated \n",
    "    \n",
    "    label_binarizer = LabelBinarizer().fit(y_test)\n",
    "    y_onehot_test = label_binarizer.transform(y_test)\n",
    "    y_onehot_test.shape  # (n_samples, n_classes)\n",
    "\n",
    "    y_score = model.predict(X_test) # y_score is onehot\n",
    "    \n",
    "    # store the fpr, tpr, and roc_auc for all averaging strategies\n",
    "    fpr, tpr, roc_auc = dict(), dict(), dict()\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_onehot_test.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    print(f\"Micro-averaged One-vs-Rest ROC AUC score:\\n{roc_auc['micro']:.2f}\")\n",
    "    \n",
    "    n_classes = n_class\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_onehot_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    fpr_grid = np.linspace(0.0, 1.0, 1000)\n",
    "\n",
    "    # Interpolate all ROC curves at these points\n",
    "    mean_tpr = np.zeros_like(fpr_grid)\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += np.interp(fpr_grid, fpr[i], tpr[i])  # linear interpolation\n",
    "\n",
    "    # Average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = fpr_grid\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    print(f\"Macro-averaged One-vs-Rest ROC AUC score:\\n{roc_auc['macro']:.2f}\")\n",
    "    \n",
    "    target_names = ['Naive','Week1','Week7']\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "    plt.plot(\n",
    "        fpr[\"micro\"],\n",
    "        tpr[\"micro\"],\n",
    "        label=f\"micro-average ROC curve (AUC = {roc_auc['micro']:.2f})\",\n",
    "        color=\"deeppink\",\n",
    "        linestyle=\":\",\n",
    "        linewidth=4,\n",
    "    )\n",
    "\n",
    "    plt.plot(\n",
    "        fpr[\"macro\"],\n",
    "        tpr[\"macro\"],\n",
    "        label=f\"macro-average ROC curve (AUC = {roc_auc['macro']:.2f})\",\n",
    "        color=\"navy\",\n",
    "        linestyle=\":\",\n",
    "        linewidth=4,\n",
    "    )\n",
    "\n",
    "    colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
    "    for class_id, color in zip(range(n_classes), colors):\n",
    "        RocCurveDisplay.from_predictions(\n",
    "            y_onehot_test[:, class_id],\n",
    "            y_score[:, class_id],\n",
    "            name=f\"ROC curve for {target_names[class_id]}\",\n",
    "            color=color,\n",
    "            ax=ax,\n",
    "            plot_chance_level=(class_id == 2),\n",
    "        )\n",
    "\n",
    "    _ = ax.set(\n",
    "        xlabel=\"False Positive Rate\",\n",
    "        ylabel=\"True Positive Rate\",\n",
    "        title=\"Extension of Receiver Operating Characteristic\\nto One-vs-Rest multiclass\",\n",
    "    )\n",
    "    \n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(histories):\n",
    "    c = ['b','g','r','c','m','y','k','w']\n",
    "    ltr = ['fold 1(train)','fold 2(train)','fold 3(train)','fold 4(train)','fold 5(train)']\n",
    "    lts = ['fold 1(val)','fold 2(val)','fold 3(val)','fold 4(val)','fold 5(val)']\n",
    "    for i in range(len(histories)):\n",
    "        # plot loss\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.title('Cross Entropy Loss')\n",
    "        plt.plot(histories[i].history['loss'], color=c[i], label=ltr[i], linestyle=\"-\")\n",
    "        plt.plot(histories[i].history['val_loss'], color=c[i], label=lts[i], linestyle=\"--\")\n",
    "        # plot accuracy\n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.title('Classification Accuracy')\n",
    "        plt.plot(histories[i].history['Accuracy'], color=c[i], label=ltr[i], linestyle=\"-\")\n",
    "        plt.plot(histories[i].history['val_Accuracy'], color=c[i], label=lts[i], linestyle=\"--\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# summarize model performance\n",
    "def summarize_performance(scores):\n",
    "    # print summary\n",
    "    print('Accuracy: mean=%.3f std=%.3f, n=%d' % (np.mean(scores)*100, np.std(scores)*100, len(scores)))\n",
    "    # box and whisker plots of results\n",
    "    plt.boxplot(scores)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08627ebe-a7e5-4c2c-a81f-5c3fd1f67025",
   "metadata": {},
   "source": [
    "# Just brain. Female. Naive vs CPH\n",
    "1) Naive (CPH_BL)\n",
    "2) CPH (CPH_W7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31333e60-218e-4b1a-bd56-598d92c0dc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "female = [49,50,51,52,65,66,77,78,79,80,81,82,83]\n",
    "#female = [49,50,51,52,65,66,77,78,79]\n",
    "y_female = np.ones(len(female))\n",
    "\n",
    "subjects = np.array(female)\n",
    "labels = np.array(list(y_female))\n",
    "sessions = [1,3]\n",
    "MRI_type = \"func\"\n",
    "functional_type = \"rest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b11c966a-ca55-4ed6-a631-775f18290343",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: a01067716 (a01067716-tecnol-gico-de-monterrey) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5861269-6b1d-4a43-a0cd-abc4f3adbad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run # 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.1s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\wandb\\run-20250912_111512-x7ut0ubc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/a01067716-tecnol-gico-de-monterrey/FEMALE_Naive_vs_CPH%28BLvsW7%29/runs/x7ut0ubc' target=\"_blank\">easy-thunder-8</a></strong> to <a href='https://wandb.ai/a01067716-tecnol-gico-de-monterrey/FEMALE_Naive_vs_CPH%28BLvsW7%29' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/a01067716-tecnol-gico-de-monterrey/FEMALE_Naive_vs_CPH%28BLvsW7%29' target=\"_blank\">https://wandb.ai/a01067716-tecnol-gico-de-monterrey/FEMALE_Naive_vs_CPH%28BLvsW7%29</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/a01067716-tecnol-gico-de-monterrey/FEMALE_Naive_vs_CPH%28BLvsW7%29/runs/x7ut0ubc' target=\"_blank\">https://wandb.ai/a01067716-tecnol-gico-de-monterrey/FEMALE_Naive_vs_CPH%28BLvsW7%29/runs/x7ut0ubc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub train:\n",
      "['F:/rabies/preprocess_batch-002_rest/bold_datasink/commonspace_bold/_scan_info_subject_id083.session01_split_name_sub-083_ses-01_desc-o_T2w/_run_None/sub-083_ses-01_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-001_rest/bold_datasink/commonspace_bold/_scan_info_subject_id052.session01_split_name_sub-052_ses-01_desc-o_T2w/_run_None/sub-052_ses-01_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-002_rest/bold_datasink/commonspace_bold/_scan_info_subject_id082.session01_split_name_sub-082_ses-01_desc-o_T2w/_run_None/sub-082_ses-01_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-001_rest/bold_datasink/commonspace_bold/_scan_info_subject_id051.session01_split_name_sub-051_ses-01_desc-o_T2w/_run_None/sub-051_ses-01_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-001_rest/bold_datasink/commonspace_bold/_scan_info_subject_id066.session01_split_name_sub-066_ses-01_desc-o_T2w/_run_None/sub-066_ses-01_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-002_rest/bold_datasink/commonspace_bold/_scan_info_subject_id079.session01_split_name_sub-079_ses-01_desc-o_T2w/_run_None/sub-079_ses-01_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-002_rest/bold_datasink/commonspace_bold/_scan_info_subject_id080.session01_split_name_sub-080_ses-01_desc-o_T2w/_run_None/sub-080_ses-01_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-002_rest/bold_datasink/commonspace_bold/_scan_info_subject_id083.session03_split_name_sub-083_ses-03_desc-o_T2w/_run_None/sub-083_ses-03_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-001_rest/bold_datasink/commonspace_bold/_scan_info_subject_id052.session03_split_name_sub-052_ses-03_desc-o_T2w/_run_None/sub-052_ses-03_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-002_rest/bold_datasink/commonspace_bold/_scan_info_subject_id082.session03_split_name_sub-082_ses-03_desc-o_T2w/_run_None/sub-082_ses-03_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-001_rest/bold_datasink/commonspace_bold/_scan_info_subject_id051.session03_split_name_sub-051_ses-03_desc-o_T2w/_run_None/sub-051_ses-03_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-001_rest/bold_datasink/commonspace_bold/_scan_info_subject_id066.session03_split_name_sub-066_ses-03_desc-o_T2w/_run_None/sub-066_ses-03_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-002_rest/bold_datasink/commonspace_bold/_scan_info_subject_id079.session03_split_name_sub-079_ses-03_desc-o_T2w/_run_None/sub-079_ses-03_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-002_rest/bold_datasink/commonspace_bold/_scan_info_subject_id080.session03_split_name_sub-080_ses-03_desc-o_T2w/_run_None/sub-080_ses-03_task-rest_desc-oa_bold_autobox_combined.nii.gz']\n",
      "sub test:\n",
      "['F:/rabies/preprocess_batch-001_rest/bold_datasink/commonspace_bold/_scan_info_subject_id049.session01_split_name_sub-049_ses-01_desc-o_T2w/_run_None/sub-049_ses-01_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-001_rest/bold_datasink/commonspace_bold/_scan_info_subject_id050.session01_split_name_sub-050_ses-01_desc-o_T2w/_run_None/sub-050_ses-01_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-001_rest/bold_datasink/commonspace_bold/_scan_info_subject_id065.session01_split_name_sub-065_ses-01_desc-o_T2w/_run_None/sub-065_ses-01_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-002_rest/bold_datasink/commonspace_bold/_scan_info_subject_id077.session01_split_name_sub-077_ses-01_desc-o_T2w/_run_None/sub-077_ses-01_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-001_rest/bold_datasink/commonspace_bold/_scan_info_subject_id049.session03_split_name_sub-049_ses-03_desc-o_T2w/_run_None/sub-049_ses-03_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-001_rest/bold_datasink/commonspace_bold/_scan_info_subject_id050.session03_split_name_sub-050_ses-03_desc-o_T2w/_run_None/sub-050_ses-03_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-001_rest/bold_datasink/commonspace_bold/_scan_info_subject_id065.session03_split_name_sub-065_ses-03_desc-o_T2w/_run_None/sub-065_ses-03_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-002_rest/bold_datasink/commonspace_bold/_scan_info_subject_id077.session03_split_name_sub-077_ses-03_desc-o_T2w/_run_None/sub-077_ses-03_task-rest_desc-oa_bold_autobox_combined.nii.gz']\n",
      "sub val:\n",
      "['F:/rabies/preprocess_batch-002_rest/bold_datasink/commonspace_bold/_scan_info_subject_id078.session01_split_name_sub-078_ses-01_desc-o_T2w/_run_None/sub-078_ses-01_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-002_rest/bold_datasink/commonspace_bold/_scan_info_subject_id081.session01_split_name_sub-081_ses-01_desc-o_T2w/_run_None/sub-081_ses-01_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-002_rest/bold_datasink/commonspace_bold/_scan_info_subject_id078.session03_split_name_sub-078_ses-03_desc-o_T2w/_run_None/sub-078_ses-03_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-002_rest/bold_datasink/commonspace_bold/_scan_info_subject_id081.session03_split_name_sub-081_ses-03_desc-o_T2w/_run_None/sub-081_ses-03_task-rest_desc-oa_bold_autobox_combined.nii.gz']\n",
      "# sesiones Train 14\n",
      "# sesiones Test 8\n",
      "# sesiones Val 4\n",
      "Starting VGG 16 3D-----------------------------------------------------\n",
      "entra al 3\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING WandbCallback is deprecated and will be removed in a future release. Please use the WandbMetricsLogger, WandbModelCheckpoint, and WandbEvalCallback callbacks instead. See https://docs.wandb.ai/guides/integrations/keras for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 65.4418 - Accuracy: 0.5071 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\easy-thunder-8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\easy-thunder-8\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 1161s 17s/step - loss: 65.4418 - Accuracy: 0.5071 - val_loss: 63.8804 - val_Accuracy: 0.5000 - combine_metric: 0.0078\n",
      "Epoch 2/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 62.3172 - Accuracy: 0.4814 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\easy-thunder-8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\easy-thunder-8\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 989s 14s/step - loss: 62.3172 - Accuracy: 0.4814 - val_loss: 60.7034 - val_Accuracy: 0.5000 - combine_metric: 0.0082\n",
      "Epoch 3/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 59.1566 - Accuracy: 0.5033 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\easy-thunder-8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\easy-thunder-8\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 1068s 15s/step - loss: 59.1566 - Accuracy: 0.5033 - val_loss: 57.5891 - val_Accuracy: 0.5000 - combine_metric: 0.0087\n",
      "Epoch 4/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 56.1244 - Accuracy: 0.4895 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\easy-thunder-8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\easy-thunder-8\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 1146s 16s/step - loss: 56.1244 - Accuracy: 0.4895 - val_loss: 54.6357 - val_Accuracy: 0.5000 - combine_metric: 0.0092\n",
      "Epoch 5/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 53.2259 - Accuracy: 0.4952 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\easy-thunder-8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\easy-thunder-8\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 1144s 16s/step - loss: 53.2259 - Accuracy: 0.4952 - val_loss: 51.7956 - val_Accuracy: 0.5000 - combine_metric: 0.0097\n",
      "Epoch 6/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 50.4474 - Accuracy: 0.4924 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\easy-thunder-8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\easy-thunder-8\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 1067s 15s/step - loss: 50.4474 - Accuracy: 0.4924 - val_loss: 49.0818 - val_Accuracy: 0.5000 - combine_metric: 0.0102\n",
      "Epoch 7/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 47.8000 - Accuracy: 0.4938 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\easy-thunder-8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\easy-thunder-8\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 1083s 15s/step - loss: 47.8000 - Accuracy: 0.4938 - val_loss: 46.5034 - val_Accuracy: 0.5000 - combine_metric: 0.0108\n",
      "Epoch 8/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 45.2922 - Accuracy: 0.5014 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\easy-thunder-8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\easy-thunder-8\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 1125s 16s/step - loss: 45.2922 - Accuracy: 0.5014 - val_loss: 44.0689 - val_Accuracy: 0.5000 - combine_metric: 0.0113\n",
      "Epoch 9/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 42.9217 - Accuracy: 0.4762 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\easy-thunder-8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\easy-thunder-8\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 1184s 17s/step - loss: 42.9217 - Accuracy: 0.4762 - val_loss: 41.7657 - val_Accuracy: 0.5000 - combine_metric: 0.0120\n",
      "Epoch 10/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 40.6968 - Accuracy: 0.5005 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\easy-thunder-8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\easy-thunder-8\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 1038s 15s/step - loss: 40.6968 - Accuracy: 0.5005 - val_loss: 39.6146 - val_Accuracy: 0.5000 - combine_metric: 0.0126\n",
      "Duration (CNN): 3:03:45.041193\n",
      "Evaluating best epoch\n",
      "40/40 [==============================] - 55s 1s/step - loss: 39.6146 - Accuracy: 0.5000\n",
      "predicts CNN\n",
      "40/40 [==============================] - 52s 1s/step\n",
      "mislabeled subjects:\n",
      " Counter({'F:/rabies/preprocess_batch-001_rest/bold_datasink/commonspace_bold/_scan_info_subject_id049.session01_split_name_sub-049_ses-01_desc-o_T2w/_run_None/sub-049_ses-01_task-rest_desc-oa_bold_autobox_combined.nii.gz': 150, 'F:/rabies/preprocess_batch-001_rest/bold_datasink/commonspace_bold/_scan_info_subject_id050.session01_split_name_sub-050_ses-01_desc-o_T2w/_run_None/sub-050_ses-01_task-rest_desc-oa_bold_autobox_combined.nii.gz': 150, 'F:/rabies/preprocess_batch-001_rest/bold_datasink/commonspace_bold/_scan_info_subject_id065.session01_split_name_sub-065_ses-01_desc-o_T2w/_run_None/sub-065_ses-01_task-rest_desc-oa_bold_autobox_combined.nii.gz': 150, 'F:/rabies/preprocess_batch-002_rest/bold_datasink/commonspace_bold/_scan_info_subject_id077.session01_split_name_sub-077_ses-01_desc-o_T2w/_run_None/sub-077_ses-01_task-rest_desc-oa_bold_autobox_combined.nii.gz': 150})\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'resized_heatmap_cph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 192\u001b[0m\n\u001b[0;32m    190\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(cv2\u001b[38;5;241m.\u001b[39mresize(np\u001b[38;5;241m.\u001b[39mrot90(np\u001b[38;5;241m.\u001b[39marray(x_vols[index_cph])[:,i,:]),dsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m126\u001b[39m,\u001b[38;5;241m87\u001b[39m)), alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# over the cam output\u001b[39;00m\n\u001b[1;32m--> 192\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(cv2\u001b[38;5;241m.\u001b[39mresize(np\u001b[38;5;241m.\u001b[39mrot90(\u001b[43mresized_heatmap_cph\u001b[49m[:,i,:]),dsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m126\u001b[39m,\u001b[38;5;241m87\u001b[39m)), alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m,cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    193\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# display the image\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'resized_heatmap_cph' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=4, shuffle=True, random_state=1)\n",
    "\n",
    "scores, histories = list(), list()\n",
    "run = 1\n",
    "for train_ix, test_ix in kfold.split(subjects, labels):\n",
    "    print(\"Run #\",run)\n",
    "    \n",
    "    # Set default values\n",
    "    config_defaults = {\n",
    "        \"batch\": 1,\n",
    "    }\n",
    "    \n",
    "    # Initialize wandb with a sample project name\n",
    "    wandb.init(project=\"FEMALE_Naive_vs_CPH(BLvsW7)\", notes=\"No pooling. New data augmentation. Z-scoring per batch. Batch = 4. 10 epoch. Just z-scoring and applying RandomFlip. All layers gradcam. lr = 1e-5\",\n",
    "                config=config_defaults)\n",
    "\n",
    "    # Specify the other hyperparameters to the configuration.\n",
    "    wandb.config.epochs = 10\n",
    "    wandb.config.sub_batch = 30\n",
    "    wandb.config.sub_batch_ts = 30\n",
    "    wandb.config.subjects = subjects\n",
    "    wandb.config.architecture_name = \"VGG16_3D\"\n",
    "    wandb.config.dataset_name = \"NAIVE vs CPH(CPH[Bl-W1])\"\n",
    "    wandb.config.CNN_blocks = 5\n",
    "    wandb.config.sessions = sessions\n",
    "    wandb.config.vols_per_session_tr = 150 #570\n",
    "    wandb.config.vols_per_session_ts = 150 #570\n",
    "    wandb.config.initial_learning_rate = 1e-5\n",
    "    #wandb.config.lr_decay_rate = 0.95\n",
    "    wandb.config.optimizer = \"Adam\"\n",
    "    \n",
    "    sub_train = subjects[list(train_ix)]\n",
    "    y_tr_all = labels[list(train_ix)]\n",
    "    \n",
    "    val_size = max(2, int(round(0.1 * len(sub_train))))\n",
    "    \n",
    "    sub_train, sub_val, y_train, y_val  = train_test_split(sub_train, labels[list(train_ix)], test_size=val_size, random_state=42, \n",
    "                                                        stratify=y_tr_all)\n",
    "    sub_test = subjects[list(test_ix)]\n",
    "\n",
    "    \n",
    "    CPHclassTrain = FILES_and_LABELS(sub_train, sessions, MRI_type, functional_type)\n",
    "    CPHclassTest = FILES_and_LABELS(sub_test, sessions, MRI_type, functional_type)\n",
    "    CPHclassval = FILES_and_LABELS(sub_val, sessions, MRI_type, functional_type)\n",
    "        \n",
    "    X_train = CPHclassTrain.get_mask_and_bold()\n",
    "    X_test = CPHclassTest.get_mask_and_bold()\n",
    "    X_val = CPHclassval.get_mask_and_bold()\n",
    "\n",
    "    wandb.config.batch = 4\n",
    "\n",
    "    print(\"sub train:\")\n",
    "    print(np.array(X_train)[:,0])\n",
    "    print(\"sub test:\")\n",
    "    print(np.array(X_test)[:,0])\n",
    "    print(\"sub val:\")\n",
    "    print(np.array(X_val)[:,0])\n",
    "\n",
    "    print(\"# sesiones Train\",len(X_train))\n",
    "    print(\"# sesiones Test\",len(X_test))\n",
    "    print(\"# sesiones Val\",len(X_val))\n",
    "    \n",
    "    traingen = CustomDataGen(X_train, batch_size=wandb.config.batch, subbatch_size=wandb.config.sub_batch,\n",
    "                                format = \"just_brain\", vols = wandb.config.vols_per_session_tr,\n",
    "                                num_class = 2, classes = \"CPHvsNAIVEfemale\", augmentation = True)\n",
    "    traingen.on_epoch_end()\n",
    "    #Es necesario que la division entre X_test y batch_size tenga un modulo igual a 0. \n",
    "    #De otra manera el ultimo batch no lo utiliza al utilizar .predict\n",
    "    testgen  = CustomDataGen(X_test, batch_size=1,subbatch_size=wandb.config.sub_batch_ts,\n",
    "                                format = \"just_brain\", vols= wandb.config.vols_per_session_ts,\n",
    "                                num_class = 2, classes = \"CPHvsNAIVEfemale\",shuffle=False)\n",
    "    valgen  = CustomDataGen(X_val, batch_size=len(X_val),subbatch_size=30, format = \"just_brain\",vols=570, num_class = 2, classes = \"CPHvsNAIVEfemale\")\n",
    "    \n",
    "    #getting model 3D CNN\n",
    "    #callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, min_delta=0.0001)\n",
    "    print(\"Starting VGG 16 3D-----------------------------------------------------\")\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    CNN = VGG16_3D(3)\n",
    "    set_pretrained_weigths(CNN)\n",
    "\n",
    "    \"\"\"\n",
    "    lr_schedule = ExponentialDecay(wandb.config.initial_learning_rate,\n",
    "                                    decay_steps=int((wandb.config.vols_per_session_tr/wandb.config.sub_batch)*len(X_train)),\n",
    "                                    decay_rate=wandb.config.lr_decay_rate, staircase=True)\n",
    "    \"\"\"\n",
    "    CNN.compile(loss=tf.nn.softmax_cross_entropy_with_logits, optimizer=tf.keras.optimizers.Adam(learning_rate=wandb.config.initial_learning_rate),\n",
    "                    metrics=[\"Accuracy\"])\n",
    "\n",
    "    checkpoint_filepath = os.getcwd()+\"/\"+wandb.run.name\n",
    "    #'/tmp/ckpt/MalevsFemale(CPH)_3D-VGG16_flips/'+wandb.run.name\n",
    "\n",
    "    acc_loss_rate = CombineCallback()\n",
    "    \n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, monitor='combine_metric', mode='max',\n",
    "                                                            save_best_only=True)\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    print(\"Training\")\n",
    "    \n",
    "    history = CNN.fit(traingen, epochs=wandb.config.epochs, validation_data = valgen, shuffle=True,\n",
    "                        callbacks=[WandbCallback(monitor='combine_metric',mode=\"max\",save_model=(False)),acc_loss_rate,model_checkpoint_callback])\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    print('Duration (CNN): {}'.format(end_time - start_time))\n",
    "\n",
    "    print(\"Evaluating best epoch\")\n",
    "    CNN.load_weights(checkpoint_filepath)\n",
    "    CNN.compile(loss=tf.nn.softmax_cross_entropy_with_logits, optimizer=tf.keras.optimizers.Adam(learning_rate=wandb.config.initial_learning_rate),\n",
    "                    metrics=[\"Accuracy\"])\n",
    "    _,acc = CNN.evaluate(testgen, verbose=1)\n",
    "\n",
    "    y_test=[]\n",
    "    x_vols = []\n",
    "    for i in range(int(len(X_test)*(wandb.config.vols_per_session_ts/wandb.config.sub_batch_ts))):\n",
    "        x,y = testgen[i]\n",
    "        y_test.extend(y)\n",
    "        x_vols.extend(x)\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "    \n",
    "    print(\"predicts CNN\")\n",
    "    preds = tf.cast(tf.argmax(CNN.predict(testgen), axis=1), tf.int32)\n",
    "\n",
    "    #Wrong predicted subjects\n",
    "    wrong_labeled_subj = mislabeled_subj(y_test, preds, X_test, wandb.config.vols_per_session_ts)\n",
    "\n",
    "    print(\"mislabeled subjects:\\n\",wrong_labeled_subj)\n",
    "    \n",
    "    scores.append(acc)\n",
    "    histories.append(history)\n",
    "\n",
    "    #GradCam\n",
    "    #Naive\n",
    "    if not os.path.exists(os.getcwd()+\"/\"+wandb.run.name+\"/Naive\"): \n",
    "        # if the demo_folder directory is not present  \n",
    "        # then create it. \n",
    "        os.makedirs(os.getcwd()+\"/\"+wandb.run.name+\"/Naive\")\n",
    "    #CPH\n",
    "    if not os.path.exists(os.getcwd()+\"/\"+wandb.run.name+\"/CPH\"): \n",
    "        # if the demo_folder directory is not present  \n",
    "        # then create it. \n",
    "        os.makedirs(os.getcwd()+\"/\"+wandb.run.name+\"/CPH\")\n",
    "\n",
    "    all_layers = [layer.name for layer in reversed(CNN.layers) if len(layer.output_shape) == 5 and (layer.__class__.__name__ == 'ReLU' or isinstance(layer, tf.keras.layers.Conv3D))]\n",
    "    \n",
    "    index_naive = index_for_gradcam(0,y_test,preds)\n",
    "    index_cph = index_for_gradcam(1,y_test,preds)\n",
    "    \n",
    "    if index_naive is not None and index_cph is not None:\n",
    "\n",
    "        # GradCAM por clase\n",
    "        heatmap_naive = make_gradcam_heatmap(np.expand_dims(x_vols[index_naive], axis=0), CNN, all_layers[0])\n",
    "        heatmap_cph   = make_gradcam_heatmap(np.expand_dims(x_vols[index_cph],   axis=0), CNN, all_layers[0])\n",
    "\n",
    "        resized_heatmap_naive = get_resized_heatmap(heatmap_naive, np.shape(x_vols[index_naive]))\n",
    "        resized_heatmap_cph   = get_resized_heatmap(heatmap_cph,   np.shape(x_vols[index_cph]))\n",
    "\n",
    "        # Animaciones coronal\n",
    "        gradcam_naive = create_animation(x_vols[index_naive], 'Naive', heatmap=resized_heatmap_naive)\n",
    "        gradcam_cph   = create_animation(x_vols[index_cph],   'CPH',   heatmap=resized_heatmap_cph)\n",
    "\n",
    "        Writer = animation.writers['ffmpeg']\n",
    "        writer = Writer(fps=15, metadata=dict(artist='Me'), bitrate=1800)\n",
    "\n",
    "        name_ani_naive = os.getcwd() + \"/\" + wandb.run.name + \"/Naive/GradCam_Naive(BlVsW1-CPH).mp4\"\n",
    "        gradcam_naive.save(name_ani_naive, writer=writer)\n",
    "\n",
    "        name_ani_CPH = os.getcwd() + \"/\" + wandb.run.name + \"/CPH/GradCam_CPH(BlVsW1-CPH).mp4\"\n",
    "        gradcam_cph.save(name_ani_CPH, writer=writer)\n",
    "\n",
    "        # GradCAM promedio de todas las capas convolucionales\n",
    "        print(\"GradCam All ConvLayers\")\n",
    "        all_layers_gradcam_naive = fuse_layers(all_layers, CNN, x_vols, index_naive, emphasize=False)\n",
    "        all_layers_gradcam_cph   = fuse_layers(all_layers, CNN, x_vols, index_cph,   emphasize=False)\n",
    "\n",
    "        all_layers_animation_naive = create_animation(x_vols[index_naive], 'all_layers_gradcam_Naive', heatmap=all_layers_gradcam_naive)\n",
    "        all_layers_animation_cph   = create_animation(x_vols[index_cph],   'all_layers_gradcam_CPH',   heatmap=all_layers_gradcam_cph)\n",
    "\n",
    "        name_all_naive = os.getcwd() + \"/\" + wandb.run.name + \"/Naive/all_layers_gradcam_Naive.mp4\"\n",
    "        all_layers_animation_naive.save(name_all_naive, writer=writer)\n",
    "\n",
    "        name_all_cph = os.getcwd() + \"/\" + wandb.run.name + \"/CPH/all_layers_gradcam_CPH.mp4\"\n",
    "        all_layers_animation_cph.save(name_all_cph, writer=writer)\n",
    "\n",
    "        # Guardar PNGs frame por frame\n",
    "        for i in range(len(x_vols[index_cph][0,:,0])):\n",
    "            plt.imshow(cv2.resize(np.rot90(np.array(x_vols[index_cph])[:,i,:]), dsize=(126,87)), alpha=0.8, cmap='bone')\n",
    "            plt.imshow(cv2.resize(np.rot90(resized_heatmap_cph[:,i,:]), dsize=(126,87)), alpha=0.4, cmap='jet')\n",
    "            plt.axis('off')\n",
    "            plt.savefig(os.getcwd()+\"/\"+wandb.run.name+\"/CPH/\"+str(i)+\".png\")\n",
    "            plt.show()\n",
    "\n",
    "        for i in range(len(x_vols[index_naive][0,:,0])):\n",
    "            plt.imshow(cv2.resize(np.rot90(np.array(x_vols[index_naive])[:,i,:]), dsize=(126,87)), alpha=0.8, cmap='bone')\n",
    "            plt.imshow(cv2.resize(np.rot90(resized_heatmap_naive[:,i,:]), dsize=(126,87)), alpha=0.4, cmap='jet')\n",
    "            plt.axis('off')\n",
    "            plt.savefig(os.getcwd()+\"/\"+wandb.run.name+\"/Naive/\"+str(i)+\".png\")\n",
    "            plt.show()\n",
    "\n",
    "        # Guardar arrays GradCAM\n",
    "        np.save(os.getcwd()+\"/\"+wandb.run.name+\"/CPH/Array_GradCam-CPH\", resized_heatmap_cph)\n",
    "        np.save(os.getcwd()+\"/\"+wandb.run.name+\"/Naive/Array_GradCam-Naive\", resized_heatmap_naive)\n",
    "\n",
    "        print(\"CM CNN\")\n",
    "        cm = confusionmatrix(y_test, preds)\n",
    "\n",
    "        # Log completo en Weights & Biases\n",
    "        wandb.log({\n",
    "            'test_acc': float(acc),\n",
    "            'time_running': '{}'.format(end_time - start_time),\n",
    "            'confution_matrix': wandb.Image(cm),\n",
    "            'mislabeled_subj': wrong_labeled_subj,\n",
    "            'GradCam_Naive-coronal': wandb.Video(name_ani_naive),\n",
    "            'GradCam-CPH-coronal': wandb.Video(name_ani_CPH),\n",
    "            'GradCam_Naive_all-layers': wandb.Video(name_all_naive),\n",
    "            'GradCam-CPH_all-layers': wandb.Video(name_all_cph),\n",
    "            'GradCam-per_frames-Naive': wandb.Image(grad_cam_per_frames(x_vols[index_naive], resized_heatmap_naive, threshold=0.3)),\n",
    "            'GradCam-per_frames-CPH': wandb.Image(grad_cam_per_frames(x_vols[index_cph], resized_heatmap_cph, threshold=0.3))\n",
    "        })\n",
    "\n",
    "else:\n",
    "    print(\" No hubo sujetos correctamente clasificados en una o ambas clases. No se generan Grad-CAMs.\")\n",
    "    wandb.log({\n",
    "        'test_acc': float(acc),\n",
    "        'time_running': '{}'.format(end_time - start_time),\n",
    "        'mislabeled_subj': wrong_labeled_subj\n",
    "    })\n",
    "    \n",
    "\n",
    "run = run + 1\n",
    "        \n",
    "print(\"histories and scores from VGG 16 M2D\") \n",
    "summarize_diagnostics(histories)\n",
    "summarize_performance(scores)\n",
    "\n",
    "wandb.finish()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d063d1a-fb21-45e2-b501-f18bb4387e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1_male = \"C:/Users/gdaalumno/OneDrive - Instituto Tecnologico y de Estudios Superiores de Monterrey/PainClassifier/Transfer Learning/VGG 16/FEMALE_Naive_vs_CPH(BLvsW7)/northern-spaceship-9/Naive/Array_GradCam-Naive.npy\"\n",
    "path2_male = \"C:/Users/gdaalumno/OneDrive - Instituto Tecnologico y de Estudios Superiores de Monterrey/PainClassifier/Transfer Learning/VGG 16/FEMALE_Naive_vs_CPH(BLvsW7)/divine-microwave-10/Naive/Array_GradCam-Naive.npy\"\n",
    "path3_male = \"C:/Users/gdaalumno/OneDrive - Instituto Tecnologico y de Estudios Superiores de Monterrey/PainClassifier/Transfer Learning/VGG 16/FEMALE_Naive_vs_CPH(BLvsW7)/deep-smoke-11/Naive/Array_GradCam-Naive.npy\"\n",
    "path4_male = \"C:/Users/gdaalumno/OneDrive - Instituto Tecnologico y de Estudios Superiores de Monterrey/PainClassifier/Transfer Learning/VGG 16/FEMALE_Naive_vs_CPH(BLvsW7)/vague-forest-12/Naive/Array_GradCam-Naive.npy\"\n",
    "\n",
    "cam1 = np.load(path1_male)\n",
    "cam2 = np.load(path2_male)\n",
    "cam3 = np.load(path3_male)\n",
    "cam4 = np.load(path4_male)\n",
    "\n",
    "avgcam = np.mean(np.array([cam1,\n",
    "                           cam2,\n",
    "                           cam3,\n",
    "                           cam4]),axis=0)\n",
    "\n",
    "print(\"max\",avgcam.max())\n",
    "print(\"min\",avgcam.min())\n",
    "\n",
    "MRI_type = \"func\"\n",
    "functional_type = \"rest\"\n",
    "CPHclassTrain = FILES_and_LABELS([82], [1], MRI_type, functional_type)\n",
    "\n",
    "X_train = CPHclassTrain.get_mask_and_bold()\n",
    "traingen = CustomDataGen(X_train, batch_size=1, subbatch_size=30,\n",
    "                                 format = \"just_brain\", vols = 570,\n",
    "                                 num_class = 2, classes = \"sex\")\n",
    "\n",
    "x,y = traingen[0]\n",
    "\n",
    "grad_cam_per_frames(x[25],avgcam,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5596f4b1-ec02-4f5e-b07f-f16ef24a1744",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/gdaalumno/OneDrive - Instituto Tecnologico y de Estudios Superiores de Monterrey/PainClassifier/Transfer Learning/VGG 16/FEMALE_Naive_vs_CPH(BLvsW7)/northern-spaceship-9/CPH/Array_GradCam-CPH.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m path3_male \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/gdaalumno/OneDrive - Instituto Tecnologico y de Estudios Superiores de Monterrey/PainClassifier/Transfer Learning/VGG 16/FEMALE_Naive_vs_CPH(BLvsW7)/deep-smoke-11/CPH/Array_GradCam-CPH.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m path4_male \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/gdaalumno/OneDrive - Instituto Tecnologico y de Estudios Superiores de Monterrey/PainClassifier/Transfer Learning/VGG 16/FEMALE_Naive_vs_CPH(BLvsW7)/vague-forest-12/CPH/Array_GradCam-CPH.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 6\u001b[0m cam1 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath1_male\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m cam2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(path2_male)\n\u001b[0;32m      8\u001b[0m cam3 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(path3_male)\n",
      "File \u001b[1;32mc:\\Users\\PC-EIAD209\\.conda\\envs\\nipd\\lib\\site-packages\\numpy\\lib\\npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/gdaalumno/OneDrive - Instituto Tecnologico y de Estudios Superiores de Monterrey/PainClassifier/Transfer Learning/VGG 16/FEMALE_Naive_vs_CPH(BLvsW7)/northern-spaceship-9/CPH/Array_GradCam-CPH.npy'"
     ]
    }
   ],
   "source": [
    "path1_male = \"C:/Users/gdaalumno/OneDrive - Instituto Tecnologico y de Estudios Superiores de Monterrey/PainClassifier/Transfer Learning/VGG 16/FEMALE_Naive_vs_CPH(BLvsW7)/northern-spaceship-9/CPH/Array_GradCam-CPH.npy\"\n",
    "path2_male = \"C:/Users/gdaalumno/OneDrive - Instituto Tecnologico y de Estudios Superiores de Monterrey/PainClassifier/Transfer Learning/VGG 16/FEMALE_Naive_vs_CPH(BLvsW7)/divine-microwave-10/CPH/Array_GradCam-CPH.npy\"\n",
    "path3_male = \"C:/Users/gdaalumno/OneDrive - Instituto Tecnologico y de Estudios Superiores de Monterrey/PainClassifier/Transfer Learning/VGG 16/FEMALE_Naive_vs_CPH(BLvsW7)/deep-smoke-11/CPH/Array_GradCam-CPH.npy\"\n",
    "path4_male = \"C:/Users/gdaalumno/OneDrive - Instituto Tecnologico y de Estudios Superiores de Monterrey/PainClassifier/Transfer Learning/VGG 16/FEMALE_Naive_vs_CPH(BLvsW7)/vague-forest-12/CPH/Array_GradCam-CPH.npy\"\n",
    "\n",
    "cam1 = np.load(path1_male)\n",
    "cam2 = np.load(path2_male)\n",
    "cam3 = np.load(path3_male)\n",
    "cam4 = np.load(path4_male)\n",
    "\n",
    "avgcam = np.mean(np.array([cam1,\n",
    "                           cam2,\n",
    "                           cam3,\n",
    "                           cam4]),axis=0)\n",
    "\n",
    "print(\"max\",avgcam.max())\n",
    "print(\"min\",avgcam.min())\n",
    "\n",
    "MRI_type = \"func\"\n",
    "functional_type = \"rest\"\n",
    "CPHclassTrain = FILES_and_LABELS([82], [3], MRI_type, functional_type)\n",
    "\n",
    "X_train = CPHclassTrain.get_mask_and_bold()\n",
    "traingen = CustomDataGen(X_train, batch_size=1, subbatch_size=30,\n",
    "                                 format = \"just_brain\", vols = 570,\n",
    "                                 num_class = 2, classes = \"sex\")\n",
    "\n",
    "x,y = traingen[0]\n",
    "\n",
    "grad_cam_per_frames(x[25],avgcam,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ff0d03-9aa6-4d24-a801-ef2c02e94eba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
