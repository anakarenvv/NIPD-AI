{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "930cb9b3-1016-4140-92f8-8e9510bf99a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"C:/Users/PC-EIAD209/Desktop/AnaKei/NIPD-AI\")\n",
    "#sys.path.append(\"C:\\\\Users\\\\\"+os.getlogin()+\"\\\\OneDrive - Instituto Tecnologico y de Estudios Superiores de Monterrey\\\\PainClassifier\")\n",
    "from my_data_generator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b514f89d-e9b9-4ecb-afa9-84963e04971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import os\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "import warnings\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support as score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from datetime import datetime\n",
    "import scipy as sp\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.utils import resample\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Conv3D, MaxPooling3D, Flatten, Dropout, GlobalAveragePooling3D, concatenate, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "\n",
    "#from keras.regularizers import l2\n",
    "import cv2\n",
    "#from keras import initializers\n",
    "#from keras.layers import LeakyReLU\n",
    "#from keras.layers import BatchNormalization\n",
    "import tensorflow as tf\n",
    "#from keras import losses\n",
    "\n",
    "#nuevo\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import initializers, losses\n",
    "from tensorflow.keras.layers import LeakyReLU, BatchNormalization\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import wandb\n",
    "from wandb.integration.keras import WandbCallback\n",
    "import gc\n",
    "#from numba import cuda   nota: no se usa\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "import nibabel as nib\n",
    "#from skiimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad5cd65c-6ba9-4dae-b349-b042293143da",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55689aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rabies_ref shape: (48, 81, 48, 620)\n"
     ]
    }
   ],
   "source": [
    "rabies_ref_path= r\"F:/rabies/preprocess_batch-001/commonspace_bold/_scan_info_subject_id003.session01_split_name_sub-003_ses-01_desc-o_T2w/_run_None/sub-003_ses-01_task-dist_desc-oa_bold_autobox_combined.nii.gz\"\n",
    "rabies_ref = nib.load(rabies_ref_path).get_fdata()\n",
    "rabies_vol= np.mean(rabies_ref, axis=3)\n",
    "print(\"rabies_ref shape:\", rabies_ref.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93afc1b9-732d-4691-bdee-14840855df92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixed precision training\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('float32')\n",
    "\n",
    "#DirectML no se lleva com mixedfloat16\n",
    "#mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1dc7abe-1101-4633-9fe8-7200ae647614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG16_3D(blocks):\n",
    "        \n",
    "    inputs = Input(shape=(42, 65, 29), name='input_layer')\n",
    "    x = Reshape(target_shape=[42, 65, 29, 1], name='input_x_3d_volumes')(inputs)\n",
    "\n",
    "    if blocks == 1:\n",
    "        print(\"entra al 1\")\n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 1st Conv Block\n",
    "        x = Conv3D(filters =64, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = Conv3D(filters =64, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.GlobalAveragePooling3D()(x)\n",
    "        x = tf.keras.layers.Dropout(0.5)(x)\n",
    "        \n",
    "    elif blocks == 2:\n",
    "        print(\"entra al 2\")\n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 1st Conv Block\n",
    "        x = Conv3D(filters =64, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = Conv3D(filters =64, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "            \n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 2nd Conv Block\n",
    "        x = Conv3D (filters =128, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = Conv3D (filters =128, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.GlobalAveragePooling3D()(x)\n",
    "        x = tf.keras.layers.Dropout(0.5)(x)\n",
    "        \n",
    "    elif blocks == 3:\n",
    "        print(\"entra al 3\")\n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 1st Conv Block\n",
    "        x = Conv3D(filters =64, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = Conv3D(filters =64, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "            \n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 2nd Conv Block\n",
    "        x = Conv3D (filters =128, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = Conv3D (filters =128, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "        \n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 3rd Conv block  \n",
    "        x = Conv3D (filters =256, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x) \n",
    "        x = Conv3D (filters =256, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x) \n",
    "        x = Conv3D (filters =256, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x) \n",
    "        x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.GlobalAveragePooling3D()(x)\n",
    "        x = tf.keras.layers.Dropout(0.5)(x)\n",
    "        \n",
    "    elif blocks == 4:\n",
    "        print(\"entra al 4\")\n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 1st Conv Block\n",
    "        x = Conv3D(filters =64, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = Conv3D(filters =64, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "            \n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 2nd Conv Block\n",
    "        x = Conv3D (filters =128, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = Conv3D (filters =128, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        #x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "        \n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 3rd Conv block  \n",
    "        x = Conv3D (filters =256, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x) \n",
    "        x = Conv3D (filters =256, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x) \n",
    "        x = Conv3D (filters =256, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x) \n",
    "        #x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "        \n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 4th Conv block\n",
    "        x = Conv3D (filters =512, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = Conv3D (filters =512, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = Conv3D (filters =512, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        #x = tf.keras.layers.GlobalAveragePooling3D()(x)\n",
    "        x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "    elif blocks == 5:\n",
    "        print(\"entra al 5\")\n",
    "        #batch_norm\n",
    "        #x = BatchNormalization()(x)\n",
    "        # 1st Conv Block\n",
    "        x = Conv3D(filters =64, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.001))(x)\n",
    "        x = Conv3D(filters =64, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.001))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.Dropout(0.1)(x)\n",
    "            \n",
    "        #batch_norm\n",
    "        #x = BatchNormalization()(x)\n",
    "        # 2nd Conv Block\n",
    "        x = Conv3D (filters =128, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.001))(x)\n",
    "        x = Conv3D (filters =128, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.001))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        #x = MaxPooling3D(pool_size =2, strides =1, padding ='same')(x)\n",
    "        x = tf.keras.layers.Dropout(0.1)(x)\n",
    "        \n",
    "        #batch_norm\n",
    "        #x = BatchNormalization()(x)\n",
    "        # 3rd Conv block  \n",
    "        x = Conv3D (filters =256, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.001))(x) \n",
    "        x = Conv3D (filters =256, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.001))(x) \n",
    "        x = Conv3D (filters =256, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.001))(x) \n",
    "        x = BatchNormalization()(x)\n",
    "        #x = MaxPooling3D(pool_size =2, strides =1, padding ='same')(x)\n",
    "        x = tf.keras.layers.Dropout(0.1)(x)\n",
    "        \n",
    "        #batch_norm\n",
    "        #x = BatchNormalization()(x)\n",
    "        # 4th Conv block\n",
    "        x = Conv3D (filters =512, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.001))(x)\n",
    "        x = Conv3D (filters =512, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.001))(x)\n",
    "        x = Conv3D (filters =512, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.001))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        #x = MaxPooling3D(pool_size =2, strides =1, padding ='same')(x)\n",
    "        x = tf.keras.layers.Dropout(0.1)(x)\n",
    "    \n",
    "        #batch_norm\n",
    "        #x = BatchNormalization()(x)\n",
    "        # 5th Conv block\n",
    "        x = Conv3D (filters =512, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.001))(x)\n",
    "        x = Conv3D (filters =512, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.001))(x)\n",
    "        x = Conv3D (filters =512, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.001))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        #x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.GlobalAveragePooling3D()(x)\n",
    "        x = tf.keras.layers.Dropout(0.1)(x)\n",
    "    \n",
    "    # Fully connected layers  \n",
    "    x = Flatten()(x) \n",
    "    x = Dense(units = 1024, activation ='relu',kernel_regularizer='l2')(x)\n",
    "    #x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = Dense(units = 1024, activation ='relu',kernel_regularizer='l2')(x) \n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    output = Dense(units = 2,activation ='softmax',kernel_regularizer='l2')(x)\n",
    "    \n",
    "    # creating the model\n",
    "    VGG_3d_model = Model (inputs=inputs, outputs =output)\n",
    "    #model.summary()\n",
    "\n",
    "    return VGG_3d_model\n",
    "\n",
    "def set_pretrained_weigths(VGG_3d_model):\n",
    "    #VGG 16 with weights from Imagenet\n",
    "    pretrained_model = tf.keras.applications.VGG16(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        pooling='avg',\n",
    "        input_shape = (42, 65, 3)\n",
    "    )\n",
    "    \n",
    "    #conv layers on VGG_3d_model\n",
    "    layers_conv = []\n",
    "    for j in range(len(VGG_3d_model.layers)):\n",
    "        if \"conv3d\" in str(VGG_3d_model.layers[j]):\n",
    "            layers_conv.append(j)\n",
    "    layers_conv_pretrained = []\n",
    "    for j in range(len(pretrained_model.layers)):\n",
    "        if \"Conv2D\" in str(pretrained_model.layers[j]):\n",
    "            layers_conv_pretrained.append(j)\n",
    "    \n",
    "    for i in range(len(layers_conv)):\n",
    "        if \"Conv2D\" in str(pretrained_model.layers[layers_conv_pretrained[i]]):\n",
    "            if i == 0:\n",
    "                w = pretrained_model.layers[layers_conv_pretrained[i]].get_weights()[0].sum(axis=2, keepdims=True)\n",
    "            else:\n",
    "                w = pretrained_model.layers[layers_conv_pretrained[i]].get_weights()[0]\n",
    "                \n",
    "            w3d=[]\n",
    "            \n",
    "            w = np.reshape(w,(3,3,-1),order='F')\n",
    "            for j in range(len(w[0,0,:])):\n",
    "                for k in range(3):\n",
    "                    w3d.append(w[:,:,j])\n",
    "            w3d = np.transpose(w3d, (1,2,0))\n",
    "            \n",
    "            new_weights = np.reshape(w3d, np.array(VGG_3d_model.layers[layers_conv[i]].get_weights()[0]).shape,order='F')\n",
    "            new_bias = pretrained_model.layers[layers_conv_pretrained[i]].get_weights()[1]\n",
    "            \n",
    "            WnB = []\n",
    "            WnB.append(new_weights)\n",
    "            WnB.append(new_bias)\n",
    "    \n",
    "            VGG_3d_model.layers[layers_conv[i]].set_weights(WnB)\n",
    "\n",
    "    del pretrained_model, w, WnB, new_weights, new_bias, w3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf8e2858-67dd-4134-a5a1-63366a491da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionmatrix_multiclass(y_test,pred):\n",
    "    cm = confusion_matrix(y_test, (np.rint(preds)).astype(int) )\n",
    "    group_names = ['True baseline','False Baseline','False Baseline',   \n",
    "                   'False week 1','Truec','False Week 1',\n",
    "                  'False week 7','False week 7','True week 7']\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                    cm.flatten()]\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                         np.ndarray.flatten(cm/(np.sum(cm,axis=1).reshape(3,1)))]\n",
    "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "              zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(3,3)\n",
    "    sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', xticklabels = ['Baseline','Week 1','Week 7'] ,yticklabels = ['Baseline','Week 1','Week 7'])\n",
    "    plt.show()\n",
    "\n",
    "def confusionmatrix(y_test,preds):\n",
    "    #Construct the Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    group_names = ['True Male','False Male','False Female','True Female']\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                    cm.flatten()]\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                         np.ndarray.flatten(cm/(np.sum(cm,axis=1).reshape(2,1)))]\n",
    "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "              zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', xticklabels = ['MALE','FEMALE'] ,yticklabels = ['MALE','FEMALE'])\n",
    "    plt.show()\n",
    "    return sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', xticklabels = ['MALE','FEMALE'] ,yticklabels = ['MALE','FEMALE'])\n",
    "    \n",
    "def confusionmatrix_binary(y_test, preds):\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    group_names = ['True baseline','False baseline','False Week 1','True Week 1']\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                    cm.flatten()]\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                         np.ndarray.flatten(cm/(np.sum(cm,axis=1).reshape(2,1)))]\n",
    "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "              zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', xticklabels = ['MALE','FEMALE'] ,yticklabels = ['MALE','FEMALE'])\n",
    "    plt.show()\n",
    "\n",
    "def ROC(probs,y_test): #binary\n",
    "    #Classification Area under curve\n",
    "     warnings.filterwarnings('ignore')\n",
    "             \n",
    "     auc = roc_auc_score(y_test, probs)\n",
    "     print('AUC - Test Set: %.2f%%' % (auc*100))\n",
    "    \n",
    "     # calculate roc curve\n",
    "     fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "     # plot no skill\n",
    "     plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "     # plot the roc curve for the model\n",
    "     plt.plot(fpr, tpr, marker='.')\n",
    "     plt.xlabel('False positive rate')\n",
    "     plt.ylabel('Sensitivity/ Recall')\n",
    "     # show the plot\n",
    "     plt.show()\n",
    "    \n",
    "     probs = (np.rint(probs)).astype(int)   \n",
    "        \n",
    "     precision = precision_score(y_test, probs)\n",
    "     print('Precision: %f' % precision)\n",
    "     # recall: tp / (tp + fn)\n",
    "     recall = recall_score(y_test, probs)\n",
    "     print('Recall: %f' % recall)\n",
    "     # f1: tp / (tp + fp + fn)\n",
    "     f1 = f1_score(y_test, probs)\n",
    "     print('F1 score: %f' % f1)\n",
    "        \n",
    "def ROC_multiclass(model, y_test, n_class):\n",
    "    #y_test: array size (# of subjects, ) with classes \n",
    "    #pretrained model to be evaluated \n",
    "    \n",
    "    label_binarizer = LabelBinarizer().fit(y_test)\n",
    "    y_onehot_test = label_binarizer.transform(y_test)\n",
    "    y_onehot_test.shape  # (n_samples, n_classes)\n",
    "\n",
    "    y_score = model.predict(X_test) # y_score is onehot\n",
    "    \n",
    "    # store the fpr, tpr, and roc_auc for all averaging strategies\n",
    "    fpr, tpr, roc_auc = dict(), dict(), dict()\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_onehot_test.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    print(f\"Micro-averaged One-vs-Rest ROC AUC score:\\n{roc_auc['micro']:.2f}\")\n",
    "    \n",
    "    n_classes = n_class\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_onehot_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    fpr_grid = np.linspace(0.0, 1.0, 1000)\n",
    "\n",
    "    # Interpolate all ROC curves at these points\n",
    "    mean_tpr = np.zeros_like(fpr_grid)\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += np.interp(fpr_grid, fpr[i], tpr[i])  # linear interpolation\n",
    "\n",
    "    # Average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = fpr_grid\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    print(f\"Macro-averaged One-vs-Rest ROC AUC score:\\n{roc_auc['macro']:.2f}\")\n",
    "    \n",
    "    target_names = ['Naive','Week1','Week7']\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "    plt.plot(\n",
    "        fpr[\"micro\"],\n",
    "        tpr[\"micro\"],\n",
    "        label=f\"micro-average ROC curve (AUC = {roc_auc['micro']:.2f})\",\n",
    "        color=\"deeppink\",\n",
    "        linestyle=\":\",\n",
    "        linewidth=4,\n",
    "    )\n",
    "\n",
    "    plt.plot(\n",
    "        fpr[\"macro\"],\n",
    "        tpr[\"macro\"],\n",
    "        label=f\"macro-average ROC curve (AUC = {roc_auc['macro']:.2f})\",\n",
    "        color=\"navy\",\n",
    "        linestyle=\":\",\n",
    "        linewidth=4,\n",
    "    )\n",
    "\n",
    "    colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
    "    for class_id, color in zip(range(n_classes), colors):\n",
    "        RocCurveDisplay.from_predictions(\n",
    "            y_onehot_test[:, class_id],\n",
    "            y_score[:, class_id],\n",
    "            name=f\"ROC curve for {target_names[class_id]}\",\n",
    "            color=color,\n",
    "            ax=ax,\n",
    "            plot_chance_level=(class_id == 2),\n",
    "        )\n",
    "\n",
    "    _ = ax.set(\n",
    "        xlabel=\"False Positive Rate\",\n",
    "        ylabel=\"True Positive Rate\",\n",
    "        title=\"Extension of Receiver Operating Characteristic\\nto One-vs-Rest multiclass\",\n",
    "    )\n",
    "    \n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(histories):\n",
    "    c = ['b','g','r','c','m','y','k','w']\n",
    "    ltr = ['fold 1(train)','fold 2(train)','fold 3(train)','fold 4(train)','fold 5(train)']\n",
    "    lts = ['fold 1(val)','fold 2(val)','fold 3(val)','fold 4(val)','fold 5(val)']\n",
    "    for i in range(len(histories)):\n",
    "        # plot loss\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.title('Cross Entropy Loss')\n",
    "        plt.plot(histories[i].history['loss'], color=c[i], label=ltr[i], linestyle=\"-\")\n",
    "        plt.plot(histories[i].history['val_loss'], color=c[i], label=lts[i], linestyle=\"--\")\n",
    "        # plot accuracy\n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.title('Classification Accuracy')\n",
    "        plt.plot(histories[i].history['Accuracy'], color=c[i], label=ltr[i], linestyle=\"-\")\n",
    "        plt.plot(histories[i].history['val_Accuracy'], color=c[i], label=lts[i], linestyle=\"--\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# summarize model performance\n",
    "def summarize_performance(scores):\n",
    "    # print summary\n",
    "    print('Accuracy: mean=%.3f std=%.3f, n=%d' % (np.mean(scores)*100, np.std(scores)*100, len(scores)))\n",
    "    # box and whisker plots of results\n",
    "    plt.boxplot(scores)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710dacbe-c461-4d1d-be96-75c0a184f29e",
   "metadata": {},
   "source": [
    "# Just Brain Male-BL vs Female-BL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e33440f-8150-4310-b0c1-fe68db52d0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entra al 5\n",
      "entra al 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "male = [57, \n",
    "        #59,\n",
    "        60,73,74,93,94,95,96,98,99,100]\n",
    "female = [49,50,51,52,65,66,77,78,79,80,81,82,\n",
    "          #83\n",
    "         ]\n",
    "         \n",
    "#male = [57,60,73,74,93,]\n",
    "#female = [49,50,51,52]\n",
    "\n",
    "y_male = np.ones(len(male))\n",
    "y_female = np.zeros(len(female))\n",
    "\n",
    "subjects = np.array(male+female)\n",
    "labels = np.array(list(y_male)+list(y_female))\n",
    "sessions = [1]\n",
    "MRI_type = \"func\"\n",
    "functional_type = \"dist\"\n",
    "\n",
    "#Pretrained model to re start weights from at every fold\n",
    "baseModel = VGG16_3D(5)\n",
    "set_pretrained_weigths(baseModel)\n",
    "\n",
    "#Model that is going to be train and re started every fold\n",
    "CNN = VGG16_3D(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14529fcb-5dff-4412-8f0b-7b1e37522403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Bootstrapping Run 1/1 ===\n",
      "Run # 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: a01067716 (a01067716-tecnol-gico-de-monterrey) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.0s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\wandb\\run-20251002_140339-tqhdy701</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/a01067716-tecnol-gico-de-monterrey/Male%20vs%20Female%28CPH%29/runs/tqhdy701' target=\"_blank\">eager-oath-25</a></strong> to <a href='https://wandb.ai/a01067716-tecnol-gico-de-monterrey/Male%20vs%20Female%28CPH%29' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/a01067716-tecnol-gico-de-monterrey/Male%20vs%20Female%28CPH%29' target=\"_blank\">https://wandb.ai/a01067716-tecnol-gico-de-monterrey/Male%20vs%20Female%28CPH%29</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/a01067716-tecnol-gico-de-monterrey/Male%20vs%20Female%28CPH%29/runs/tqhdy701' target=\"_blank\">https://wandb.ai/a01067716-tecnol-gico-de-monterrey/Male%20vs%20Female%28CPH%29/runs/tqhdy701</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub train:\n",
      "['F:/rabies/preprocess_batch-002/commonspace_bold/_scan_info_subject_id100.session01_split_name_sub-100_ses-01_desc-o_T2w/_run_None/sub-100_ses-01_task-dist_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-002/commonspace_bold/_scan_info_subject_id081.session01_split_name_sub-081_ses-01_desc-o_T2w/_run_None/sub-081_ses-01_task-dist_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-001/commonspace_bold/_scan_info_subject_id057.session01_split_name_sub-057_ses-01_desc-o_T2w/_run_None/sub-057_ses-01_task-dist_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-002/commonspace_bold/_scan_info_subject_id095.session01_split_name_sub-095_ses-01_desc-o_T2w/_run_None/sub-095_ses-01_task-dist_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-002/commonspace_bold/_scan_info_subject_id079.session01_split_name_sub-079_ses-01_desc-o_T2w/_run_None/sub-079_ses-01_task-dist_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-002/commonspace_bold/_scan_info_subject_id080.session01_split_name_sub-080_ses-01_desc-o_T2w/_run_None/sub-080_ses-01_task-dist_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-002/commonspace_bold/_scan_info_subject_id095.session01_split_name_sub-095_ses-01_desc-o_T2w/_run_None/sub-095_ses-01_task-dist_desc-oa_bold_autobox_combined.nii.gz']\n",
      "sub test:\n",
      "['F:/rabies/preprocess_batch-002/commonspace_bold/_scan_info_subject_id100.session01_split_name_sub-100_ses-01_desc-o_T2w/_run_None/sub-100_ses-01_task-dist_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-002/commonspace_bold/_scan_info_subject_id073.session01_split_name_sub-073_ses-01_desc-o_T2w/_run_None/sub-073_ses-01_task-dist_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-001/commonspace_bold/_scan_info_subject_id060.session01_split_name_sub-060_ses-01_desc-o_T2w/_run_None/sub-060_ses-01_task-dist_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-001/commonspace_bold/_scan_info_subject_id049.session01_split_name_sub-049_ses-01_desc-o_T2w/_run_None/sub-049_ses-01_task-dist_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-002/commonspace_bold/_scan_info_subject_id078.session01_split_name_sub-078_ses-01_desc-o_T2w/_run_None/sub-078_ses-01_task-dist_desc-oa_bold_autobox_combined.nii.gz']\n",
      "sub val:\n",
      "['F:/rabies/preprocess_batch-002/commonspace_bold/_scan_info_subject_id080.session01_split_name_sub-080_ses-01_desc-o_T2w/_run_None/sub-080_ses-01_task-dist_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-002/commonspace_bold/_scan_info_subject_id096.session01_split_name_sub-096_ses-01_desc-o_T2w/_run_None/sub-096_ses-01_task-dist_desc-oa_bold_autobox_combined.nii.gz']\n",
      "# sesiones Train 7\n",
      "# sesiones Test 5\n",
      "# sesiones Val 2\n",
      "Starting VGG 16 3D-----------------------------------------------------\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING WandbCallback is deprecated and will be removed in a future release. Please use the WandbMetricsLogger, WandbModelCheckpoint, and WandbEvalCallback callbacks instead. See https://docs.wandb.ai/guides/integrations/keras for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "133/133 [==============================] - ETA: 0s - loss: 21.6593 - Accuracy: 0.9311 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\eager-oath-25\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\eager-oath-25\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 7011s 53s/step - loss: 21.6593 - Accuracy: 0.9311 - val_loss: 20.9193 - val_Accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - ETA: 0s - loss: 20.1810 - Accuracy: 0.9489 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\eager-oath-25\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\eager-oath-25\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 7000s 53s/step - loss: 20.1810 - Accuracy: 0.9489 - val_loss: 19.4118 - val_Accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - ETA: 0s - loss: 18.8656 - Accuracy: 0.9516 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\eager-oath-25\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\eager-oath-25\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 6985s 53s/step - loss: 18.8656 - Accuracy: 0.9516 - val_loss: 18.1184 - val_Accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - ETA: 0s - loss: 17.5930 - Accuracy: 0.9554 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\eager-oath-25\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\eager-oath-25\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 7004s 53s/step - loss: 17.5930 - Accuracy: 0.9554 - val_loss: 16.8786 - val_Accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - ETA: 0s - loss: 16.3662 - Accuracy: 0.9764 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\eager-oath-25\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\eager-oath-25\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 7014s 53s/step - loss: 16.3662 - Accuracy: 0.9764 - val_loss: 15.7473 - val_Accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - ETA: 0s - loss: 15.2660 - Accuracy: 0.9797 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\eager-oath-25\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\eager-oath-25\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 7005s 53s/step - loss: 15.2660 - Accuracy: 0.9797 - val_loss: 14.6658 - val_Accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "133/133 [==============================] - ETA: 0s - loss: 14.2248 - Accuracy: 0.9940 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\eager-oath-25\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\eager-oath-25\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 6995s 53s/step - loss: 14.2248 - Accuracy: 0.9940 - val_loss: 13.6745 - val_Accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "133/133 [==============================] - ETA: 0s - loss: 13.2603 - Accuracy: 0.9982 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\eager-oath-25\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\eager-oath-25\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 7002s 53s/step - loss: 13.2603 - Accuracy: 0.9982 - val_loss: 12.7671 - val_Accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "133/133 [==============================] - ETA: 0s - loss: 12.3771 - Accuracy: 0.9972 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\eager-oath-25\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\eager-oath-25\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 7003s 53s/step - loss: 12.3771 - Accuracy: 0.9972 - val_loss: 11.9318 - val_Accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "133/133 [==============================] - ETA: 0s - loss: 11.5599 - Accuracy: 0.9990 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\eager-oath-25\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\eager-oath-25\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 7005s 53s/step - loss: 11.5599 - Accuracy: 0.9990 - val_loss: 11.1372 - val_Accuracy: 1.0000\n",
      "Duration (CNN): 19:27:21.421564\n",
      "predicts CNN\n",
      "95/95 [==============================] - 67s 709ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    " # 80% train y val y 20% test\n",
    "\n",
    "n_bootstraps= 1\n",
    "for boot in range(n_bootstraps): \n",
    "    print(f\"\\n=== Bootstrapping Run {boot+1}/{n_bootstraps} ===\")\n",
    "\n",
    "    # Resample subjects + labels con reemplazo\n",
    "    boot_subjects, boot_labels = resample(\n",
    "     subjects, labels, replace=True, random_state=42+boot\n",
    "    )\n",
    "\n",
    "    sub_trainval, sub_test, y_trainval, y_test = train_test_split(\n",
    "    boot_subjects, boot_labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=2, shuffle=True, random_state=1)\n",
    "\n",
    "    scores, histories = list(), list()\n",
    "    run = 1\n",
    "    for train_ix, val_ix in kfold.split(sub_trainval, y_trainval):\n",
    "        print(\"Run #\",run)\n",
    "        sub_train, sub_val = boot_subjects[train_ix], boot_subjects[val_ix]\n",
    "        y_train, y_val     = boot_labels[train_ix], boot_labels[val_ix]\n",
    "\n",
    "        sub_test, y_test = sub_test, y_test\n",
    "\n",
    "        \n",
    "\n",
    "        # Set default values\n",
    "        config_defaults = {\n",
    "            \"batch\": 2,\n",
    "        }\n",
    "        # Initialize wandb with a sample project name\n",
    "        wandb.init(project=\"Male vs Female(CPH)\", notes=\"FOLD \"+str(run)+\".  Male-W7 vs Female-W7. Rest-approach on DIST data. GPT recommendations. 15 epoch. Just z-scoring and applying RandomFlip. All layers gradcam. pooling just on first block. lr = 1e-6\",\n",
    "                config=config_defaults)\n",
    "\n",
    "        # Specify the other hyperparameters to the configuration.\n",
    "        wandb.config.epochs = 10 #antes 15\n",
    "        wandb.config.sub_batch = 30\n",
    "        wandb.config.sub_batch_ts = 30\n",
    "        wandb.config.subjects = subjects\n",
    "        wandb.config.architecture_name = \"VGG16_3D\"\n",
    "        wandb.config.dataset_name = \"Male vs Female(CPH[w7])-Rest-approach_DIST-data\"\n",
    "        wandb.config.CNN_blocks = 5\n",
    "        wandb.config.sessions = sessions\n",
    "        wandb.config.vols_per_session_tr = 570 #570\n",
    "        wandb.config.vols_per_session_ts = 570 #570\n",
    "        wandb.config.initial_learning_rate = 1e-5\n",
    "        #wandb.config.lr_decay_rate = 0.95\n",
    "        wandb.config.optimizer = \"Adam\"\n",
    "        \n",
    "        #\n",
    "        val_size = max(2, int(round(0.1 * len(train_ix))))\n",
    "    \n",
    "        sub_train, sub_val, y_train, y_val = train_test_split(\n",
    "            sub_trainval[train_ix], y_trainval[train_ix],\n",
    "            test_size=val_size,  # test_size se refiere a la validacion\n",
    "            random_state=42, stratify=y_trainval[train_ix]\n",
    "        )\n",
    "\n",
    "        sub_test, y_test = sub_test, y_test\n",
    "        #\n",
    "        \n",
    "        CPHclassTrain = FILES_and_LABELS(sub_train, sessions, MRI_type, functional_type)\n",
    "        CPHclassTest = FILES_and_LABELS(sub_test, sessions, MRI_type, functional_type)\n",
    "        CPHclassval = FILES_and_LABELS(sub_val, sessions, MRI_type, functional_type)\n",
    "            \n",
    "        X_train = CPHclassTrain.get_mask_and_bold()\n",
    "        X_test = CPHclassTest.get_mask_and_bold()\n",
    "        X_val = CPHclassval.get_mask_and_bold()\n",
    "\n",
    "        print(\"sub train:\")\n",
    "        print(np.array(X_train)[:,0])\n",
    "        print(\"sub test:\")\n",
    "        print(np.array(X_test)[:,0])\n",
    "        print(\"sub val:\")\n",
    "        print(np.array(X_val)[:,0])\n",
    "\n",
    "        print(\"# sesiones Train\",len(X_train))\n",
    "        print(\"# sesiones Test\",len(X_test))\n",
    "        print(\"# sesiones Val\",len(X_val))\n",
    "        \n",
    "        traingen = CustomDataGen(X_train, batch_size=wandb.config.batch, subbatch_size=wandb.config.sub_batch,\n",
    "                                format = \"just_brain\", vols = wandb.config.vols_per_session_tr,\n",
    "                                num_class = 2, classes = \"sex\", augmentation = True, functional_type = \"rest\")\n",
    "        traingen.on_epoch_end()\n",
    "        #Es necesario que la division entre X_test y batch_size tenga un modulo igual a 0. \n",
    "        #De otra manera el ultimo batch no lo utiliza al utilizar .predict\n",
    "        testgen  = CustomDataGen(X_test, batch_size=1,subbatch_size=wandb.config.sub_batch_ts,\n",
    "                                format = \"just_brain\", vols= wandb.config.vols_per_session_ts,\n",
    "                                num_class = 2, classes = \"sex\",shuffle=False, functional_type = \"rest\")\n",
    "        valgen  = CustomDataGen(X_val, batch_size=len(X_val),subbatch_size=30, format = \"just_brain\",vols=570, augmentation = True, num_class = 2,\n",
    "                                classes = \"sex\", functional_type = \"rest\")\n",
    "        \n",
    "        #getting model 3D CNN\n",
    "        #callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, min_delta=0.0001)\n",
    "        print(\"Starting VGG 16 3D-----------------------------------------------------\")\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "\n",
    "        #transfer learning\n",
    "        layers = [l for l in CNN.layers]\n",
    "            \n",
    "        for i in range(len(baseModel.layers)):\n",
    "            layers[i].set_weights(baseModel.layers[i].get_weights())\n",
    "            \n",
    "        \"\"\"\n",
    "        lr_schedule = ExponentialDecay(wandb.config.initial_learning_rate,\n",
    "                                    decay_steps=int((wandb.config.vols_per_session_tr/wandb.config.sub_batch)*len(X_train)),\n",
    "                                    decay_rate=wandb.config.lr_decay_rate, staircase=True)\n",
    "        \"\"\"\n",
    "        CNN.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=wandb.config.initial_learning_rate),\n",
    "                        metrics=[\"Accuracy\"])\n",
    "\n",
    "        checkpoint_filepath = os.getcwd()+\"/\"+wandb.run.name\n",
    "        #'/tmp/ckpt/MalevsFemale(CPH)_3D-VGG16_flips/'+wandb.run.name\n",
    "        \n",
    "        model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_loss', mode='min',\n",
    "                                                                save_best_only=True)\n",
    "        \n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        print(\"Training\")\n",
    "        \n",
    "        history = CNN.fit(traingen, epochs=wandb.config.epochs, validation_data = valgen, shuffle=True,\n",
    "                        callbacks=[WandbCallback(monitor='val_loss',mode=\"min\",save_model=(False)),model_checkpoint_callback])\n",
    "        \n",
    "        end_time = datetime.now()\n",
    "        print('Duration (CNN): {}'.format(end_time - start_time))\n",
    "\n",
    "        y_test=[]\n",
    "        x_vols = []\n",
    "        for i in range(int(len(X_test)*(wandb.config.vols_per_session_ts/wandb.config.sub_batch_ts))):\n",
    "            x,y = testgen[i]\n",
    "            y_test.extend(y)\n",
    "            x_vols.extend(x)\n",
    "        y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "        \n",
    "        print(\"predicts CNN\")\n",
    "        preds = tf.cast(tf.argmax(CNN.predict(testgen), axis=1), tf.int32)\n",
    "\n",
    "        #Wrong predicted subjects\n",
    "        wrong_labeled_subj = mislabeled_subj(y_test, preds, X_test, wandb.config.vols_per_session_ts)\n",
    "\n",
    "        print(\"mislabeled subjects:\\n\",wrong_labeled_subj)\n",
    "        \n",
    "        print(\"evaluating CNN\")\n",
    "        _,acc = CNN.evaluate(testgen, verbose=1)\n",
    "        \n",
    "        scores.append(acc)\n",
    "        histories.append(history)\n",
    "\n",
    "        #GradCam\n",
    "        all_layers = [layer.name for layer in reversed(CNN.layers) if len(layer.output_shape) == 5 and (layer.__class__.__name__ == 'ReLU' or isinstance(layer, tf.keras.layers.Conv3D))]\n",
    "        \n",
    "        index_male = index_for_gradcam(0,y_test,preds)\n",
    "        index_female = index_for_gradcam(1,y_test,preds)\n",
    "\n",
    "        Writer = animation.writers['ffmpeg']\n",
    "        writer = Writer(fps=15, metadata=dict(artist='Me'), bitrate=1800)\n",
    "\n",
    "        if index_male is None:\n",
    "            index_male=0\n",
    "            print(\"No se encontró ningún sujeto male correctamente clasificado\")\n",
    "            \n",
    "\n",
    "        rabies_crop= rabies_vol[3:45, 4:69, 7:36] #original 48,81,48 #cropped 42,65,29\n",
    "\n",
    "        heatmap_male = make_gradcam_heatmap(np.expand_dims(x_vols[index_male], axis=0), CNN, all_layers[0])\n",
    "        resized_heatmap_male = get_resized_heatmap(heatmap_male,rabies_crop.shape[:3])\n",
    "        gradcam_male = create_animation(rabies_crop, 'Male', heatmap=resized_heatmap_male)\n",
    "        name_ani_male = \"GradCam_male(malevsfemale-CPH)-\"+wandb.run.name+\".mp4\"\n",
    "        gradcam_male.save(name_ani_male, writer=writer)\n",
    "\n",
    "        #GradCam average all conv layers\n",
    "        print(\"GradCam All ConvLayers-male\")\n",
    "\n",
    "        all_layers_gradcam_male = fuse_layers(all_layers, CNN, [x_vols[index_male]], 0, emphasize=False)\n",
    "        all_layers_animation_male = create_animation(rabies_crop, 'All_layers_GradCam_male', heatmap=all_layers_gradcam_male)\n",
    "        name_all_male = 'All_layers_GradCam_male'+wandb.run.name+'.mp4'\n",
    "        all_layers_animation_male.save(name_all_male, writer=writer)\n",
    "\n",
    "        #males\n",
    "        if not os.path.exists(os.getcwd()+\"/\"+wandb.run.name+\"/male\"): \n",
    "            # if the demo_folder directory is not present  \n",
    "            # then create it. \n",
    "            os.makedirs(os.getcwd()+\"/\"+wandb.run.name+\"/male\")\n",
    "\n",
    "        \n",
    "        full_grad_male = np.zeros_like((rabies_vol))\n",
    "        full_grad_male[3:45,4:69,7:36] = resized_heatmap_male\n",
    "    \n",
    "\n",
    "        for i in range(rabies_vol.shape[1]):\n",
    "            plt.imshow(cv2.resize(np.rot90(rabies_vol[:,i,:]),dsize=(126,87)), alpha=0.8, cmap='bone')\n",
    "            # over the cam output\n",
    "            plt.imshow(cv2.resize(np.rot90(full_grad_male[:,i,:]),dsize=(126,87)), alpha=0.4,cmap='jet')\n",
    "            plt.axis('off')\n",
    "            # display the image\n",
    "            name = str(i)+\".png\" \n",
    "            plt.savefig(os.getcwd()+\"/\"+wandb.run.name+\"/male/\"+name)\n",
    "            plt.show()\n",
    "    \n",
    "    \n",
    "        np.save(os.getcwd()+\"/\"+wandb.run.name+\"/male/Array_GradCam-M\", full_grad_male)\n",
    "        \n",
    "        wandb.log({'GradCam_Male-coronal': wandb.Video(name_ani_male),\n",
    "            'GradCam_Male_all-layers': wandb.Video(name_all_male),\n",
    "            'GradCam-per_frames-male': wandb.Image(grad_cam_per_frames(rabies_crop,resized_heatmap_male, 150))})\n",
    "\n",
    "        if index_female is None:\n",
    "            index_female=0\n",
    "            print(\"No se encontró ningún sujeto female correctamente clasificado\")\n",
    "            \n",
    "        heatmap_female = make_gradcam_heatmap(np.expand_dims(x_vols[index_female], axis=0), CNN, all_layers[0]) \n",
    "        resized_heatmap_female = get_resized_heatmap(heatmap_female, rabies_crop.shape[:3])\n",
    "        gradcam_female = create_animation(rabies_crop, 'Female', heatmap=resized_heatmap_female)\n",
    "        name_ani_female = \"GradCam_female(malevsfemale-CPH)-\"+wandb.run.name+\".mp4\"\n",
    "        gradcam_female.save(name_ani_female, writer=writer)\n",
    "    \n",
    "        #GradCam average all conv layers\n",
    "        print(\"GradCam All ConvLayers-female\")\n",
    "    \n",
    "        all_layers_gradcam_female = fuse_layers(all_layers, CNN, [x_vols[index_female]], 0, emphasize=False)\n",
    "        all_layers_animation_female = create_animation(rabies_crop, 'All_layers_GradCam_female', heatmap=all_layers_gradcam_female)\n",
    "        name_all_female = 'All_layers_GradCam_female'+wandb.run.name+'.mp4'\n",
    "        all_layers_animation_female.save(name_all_female, writer=writer)\n",
    "    \n",
    "        #Save frame by frame of gradcam\n",
    "        #Females\n",
    "        if not os.path.exists(os.getcwd()+\"/\"+wandb.run.name+\"/female\"): \n",
    "            # if the demo_folder directory is not present  \n",
    "            # then create it. \n",
    "            os.makedirs(os.getcwd()+\"/\"+wandb.run.name+\"/female\")\n",
    "\n",
    "        \n",
    "        #get gradCams with the shape of the original volumes before crop\n",
    "        full_grad_female = np.zeros_like((rabies_vol))\n",
    "        full_grad_female[3:45,4:69,7:36] = resized_heatmap_female\n",
    "        \n",
    "        \n",
    "        for i in range(rabies_vol.shape[1]):\n",
    "            plt.imshow(cv2.resize(np.rot90(rabies_vol[:,i,:]),dsize=(126,87)), alpha=0.8, cmap='bone')\n",
    "            # over the cam output\n",
    "            plt.imshow(cv2.resize(np.rot90(full_grad_female[:,i,:]),dsize=(126,87)), alpha=0.4,cmap='jet')\n",
    "            plt.axis('off')\n",
    "            # display the image\n",
    "            \n",
    "            name = str(i)+\".png\" \n",
    "            plt.savefig(os.getcwd()+\"/\"+wandb.run.name+\"/female/\"+name)\n",
    "            plt.show()\n",
    "    \n",
    "\n",
    "        np.save(os.getcwd()+\"/\"+wandb.run.name+\"/female/Array_GradCam-F\", full_grad_female)\n",
    "        wandb.log({'GradCam-Female-coronal': wandb.Video(name_ani_female),\n",
    "            'GradCam-Female_all-layers': wandb.Video(name_all_female),\n",
    "            'GradCam-per_frames-female (crop)': wandb.Image(grad_cam_per_frames(rabies_crop, resized_heatmap_female, 150))})#vista recortadfs\n",
    "     \n",
    "     \n",
    "        \n",
    "\n",
    "        print(\"CM CNN\")\n",
    "        cm = confusionmatrix(y_test, preds)\n",
    "\n",
    "        wandb.log({'test_acc': float(acc),\n",
    "                'time_running': '{}'.format(end_time - start_time),\n",
    "                'confution_matrix': wandb.Image(cm),\n",
    "                'mislabeled_subj':wrong_labeled_subj})\n",
    "        \n",
    "\n",
    "        run = run + 1\n",
    "            \n",
    "    print(\"histories and scores from VGG 16 M2D\") \n",
    "    summarize_diagnostics(histories)\n",
    "    summarize_performance(scores)\n",
    "\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nipd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
