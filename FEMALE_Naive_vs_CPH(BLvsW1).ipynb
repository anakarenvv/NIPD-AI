{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8a2d530-3ec9-42fd-be5f-e5efd35b0fa7",
   "metadata": {},
   "source": [
    "# Female Naive Vs Female CPH\n",
    "1. Female CPH (baseline)\n",
    "2. Female CPH (Week 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "106ffb1b-7a21-4433-b76f-276108f014de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"C:/Users/PC-EIAD209/Desktop/AnaKei/NIPD-AI\")\n",
    "\n",
    "#sys.path.append(\"C:\\\\Users\\\\\"+os.getlogin()+\"\\\\OneDrive - Instituto Tecnologico y de Estudios Superiores de Monterrey\\\\PainClassifier\")\n",
    "from my_data_generator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748e72bd-7f6a-4a51-9d62-8c9891680af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import scipy.io as sio\n",
    "import os\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "import warnings\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support as score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from datetime import datetime\n",
    "import scipy as sp\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Conv3D, MaxPooling3D, Flatten, Dropout, GlobalAveragePooling3D, concatenate, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import resample\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from keras.regularizers import l2\n",
    "import cv2\n",
    "from keras import initializers\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import BatchNormalization\n",
    "import tensorflow as tf\n",
    "from keras import losses\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import wandb\n",
    "from wandb.integration.keras import WandbCallback\n",
    "import gc\n",
    "#from numba import cuda\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "import nibabel as nib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21eb224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rabies_vol shape: (48, 81, 48)\n"
     ]
    }
   ],
   "source": [
    "rabies_ref_path= r\"F:/rabies/preprocess_batch-001/commonspace_bold/_scan_info_subject_id003.session01_split_name_sub-003_ses-01_desc-o_T2w/_run_None/sub-003_ses-01_task-dist_desc-oa_bold_autobox_combined.nii.gz\"\n",
    "rabies_ref = nib.load(rabies_ref_path).get_fdata()\n",
    "rabies_vol= np.mean(rabies_ref, axis=3)\n",
    "\n",
    "print(\"rabies_ref shape:\", rabies_ref.shape)\n",
    "\n",
    "'''\n",
    "rabies_ref_path= r\"F:\\New data\\sigma_files\\sigma_files\\SIGMA_resam_InVivo_Brain_Template_Masked.nii\"\n",
    "rabies_vol = nib.load(rabies_ref_path).get_fdata()\n",
    "#rabies_vol= np.mean(rabies_ref, axis=3)\n",
    "print(\"rabies_vol shape:\",rabies_vol.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43ca2d53-8010-4075-a5e1-55782abcec4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Devices:\", tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "780811a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_heatmap(heatmap, threshold=0.6):\n",
    "    \"\"\"\n",
    "    Filtra el heatmap para resaltar solo las regiones más activas\n",
    "    y lo prepara en formato uint8 para OpenCV.\n",
    "    \"\"\"\n",
    "    # Copia para no modificar el original\n",
    "    filtered = np.copy(heatmap)\n",
    "\n",
    "    # Normalizar a rango [0, 1]\n",
    "    if np.max(filtered) > 1:\n",
    "        filtered = filtered / 255.0\n",
    "\n",
    "    # Aplicar threshold adaptativo\n",
    "    dynamic_threshold = threshold * np.max(filtered)\n",
    "    filtered[filtered < dynamic_threshold] = 0\n",
    "\n",
    "    # Normalizar nuevamente entre 0–255\n",
    "    filtered = 255 * filtered / np.max(filtered) if np.max(filtered) > 0 else filtered\n",
    "\n",
    "    # ✅ Convertir a uint8 para compatibilidad con OpenCV\n",
    "    filtered = np.uint8(filtered)\n",
    "\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25446ae9-81d1-4ee5-a514-bd2439a09094",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f00cc49e-1a2f-4bc1-a9d0-f96b762bb778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG16_3D(blocks):\n",
    "        \n",
    "    inputs = Input(shape=(42, 65, 29), name='input_layer')\n",
    "    x = Reshape(target_shape=[42, 65, 29, 1], name='input_x_3d_volumes')(inputs)\n",
    "\n",
    "    if blocks == 1:\n",
    "        print(\"entra al 1\")\n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 1st Conv Block\n",
    "        x = Conv3D(filters =64, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = Conv3D(filters =64, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.GlobalAveragePooling3D()(x)\n",
    "        x = tf.keras.layers.Dropout(0.5)(x)\n",
    "        \n",
    "    elif blocks == 2:\n",
    "        print(\"entra al 2\")\n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 1st Conv Block\n",
    "        x = Conv3D(filters =64, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = Conv3D(filters =64, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "            \n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 2nd Conv Block\n",
    "        x = Conv3D (filters =128, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = Conv3D (filters =128, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.GlobalAveragePooling3D()(x)\n",
    "        x = tf.keras.layers.Dropout(0.5)(x)\n",
    "        \n",
    "    elif blocks == 3:\n",
    "        print(\"entra al 3\")\n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 1st Conv Block\n",
    "        x = Conv3D(filters =64, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = Conv3D(filters =64, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "            \n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 2nd Conv Block\n",
    "        x = Conv3D (filters =128, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = Conv3D (filters =128, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "        \n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 3rd Conv block  \n",
    "        x = Conv3D (filters =256, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x) \n",
    "        x = Conv3D (filters =256, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x) \n",
    "        x = Conv3D (filters =256, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x) \n",
    "        x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.GlobalAveragePooling3D()(x)\n",
    "        x = tf.keras.layers.Dropout(0.5)(x)\n",
    "        \n",
    "    elif blocks == 4:\n",
    "        print(\"entra al 4\")\n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 1st Conv Block\n",
    "        x = Conv3D(filters =64, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = Conv3D(filters =64, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "            \n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 2nd Conv Block\n",
    "        x = Conv3D (filters =128, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = Conv3D (filters =128, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        #x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "        \n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 3rd Conv block  \n",
    "        x = Conv3D (filters =256, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x) \n",
    "        x = Conv3D (filters =256, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x) \n",
    "        x = Conv3D (filters =256, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x) \n",
    "        #x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "        \n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 4th Conv block\n",
    "        x = Conv3D (filters =512, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = Conv3D (filters =512, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = Conv3D (filters =512, kernel_size =3, padding ='same', activation='relu',kernel_regularizer='l2')(x)\n",
    "        x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        #x = tf.keras.layers.GlobalAveragePooling3D()(x)\n",
    "        x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "    elif blocks == 5:\n",
    "        print(\"entra al 5\")\n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 1st Conv Block\n",
    "        x = Conv3D(filters =64, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.05))(x)\n",
    "        x = Conv3D(filters =64, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.05))(x)\n",
    "        x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "            \n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 2nd Conv Block\n",
    "        x = Conv3D (filters =128, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.05))(x)\n",
    "        x = Conv3D (filters =128, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.05))(x)\n",
    "        #x = MaxPooling3D(pool_size =2, strides =1, padding ='same')(x)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "        \n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 3rd Conv block  \n",
    "        x = Conv3D (filters =256, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.05))(x) \n",
    "        x = Conv3D (filters =256, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.05))(x) \n",
    "        x = Conv3D (filters =256, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.05))(x) \n",
    "        #x = MaxPooling3D(pool_size =2, strides =1, padding ='same')(x)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "        \n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 4th Conv block\n",
    "        x = Conv3D (filters =512, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.05))(x)\n",
    "        x = Conv3D (filters =512, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.05))(x)\n",
    "        x = Conv3D (filters =512, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.05))(x)\n",
    "        #x = MaxPooling3D(pool_size =2, strides =1, padding ='same')(x)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "        #batch_norm\n",
    "        x = BatchNormalization()(x)\n",
    "        # 5th Conv block\n",
    "        x = Conv3D (filters =512, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.05))(x)\n",
    "        x = Conv3D (filters =512, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.05))(x)\n",
    "        x = Conv3D (filters =512, kernel_size =3, padding ='same', activation='relu',kernel_regularizer=tf.keras.regularizers.L2(l2=0.05))(x)\n",
    "        #x = MaxPooling3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "        x = tf.keras.layers.GlobalAveragePooling3D()(x)\n",
    "        x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    \n",
    "    # Fully connected layers  \n",
    "    x = Flatten()(x) \n",
    "    x = Dense(units = 4096, activation ='relu',kernel_regularizer='l2')(x)\n",
    "    #x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = Dense(units = 4096, activation ='relu',kernel_regularizer='l2')(x) \n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    output = Dense(units = 2,activation ='sigmoid',kernel_regularizer='l2')(x)\n",
    "    \n",
    "    # creating the model\n",
    "    VGG_3d_model = Model (inputs=inputs, outputs =output)\n",
    "    #model.summary()\n",
    "\n",
    "    return VGG_3d_model\n",
    "\n",
    "def set_pretrained_weigths(VGG_3d_model):\n",
    "    #VGG 16 with weights from Imagenet\n",
    "    pretrained_model = tf.keras.applications.VGG16(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        pooling='avg',\n",
    "        input_shape = (42, 65, 3)\n",
    "    )\n",
    "    \n",
    "    #conv layers on VGG_3d_model\n",
    "    layers_conv = []\n",
    "    for j in range(len(VGG_3d_model.layers)):\n",
    "        if \"conv3d\" in str(VGG_3d_model.layers[j]):\n",
    "            layers_conv.append(j)\n",
    "    layers_conv_pretrained = []\n",
    "    for j in range(len(pretrained_model.layers)):\n",
    "        if \"Conv2D\" in str(pretrained_model.layers[j]):\n",
    "            layers_conv_pretrained.append(j)\n",
    "    \n",
    "    for i in range(len(layers_conv)):\n",
    "        if \"Conv2D\" in str(pretrained_model.layers[layers_conv_pretrained[i]]):\n",
    "            if i == 0:\n",
    "                w = pretrained_model.layers[layers_conv_pretrained[i]].get_weights()[0].sum(axis=2, keepdims=True)\n",
    "            else:\n",
    "                w = pretrained_model.layers[layers_conv_pretrained[i]].get_weights()[0]\n",
    "                \n",
    "            w3d=[]\n",
    "            \n",
    "            w = np.reshape(w,(3,3,-1),order='F')\n",
    "            for j in range(len(w[0,0,:])):\n",
    "                for k in range(3):\n",
    "                    w3d.append(w[:,:,j])\n",
    "            w3d = np.transpose(w3d, (1,2,0))\n",
    "            \n",
    "            new_weights = np.reshape(w3d, np.array(VGG_3d_model.layers[layers_conv[i]].get_weights()[0]).shape,order='F')\n",
    "            new_bias = pretrained_model.layers[layers_conv_pretrained[i]].get_weights()[1]\n",
    "            \n",
    "            WnB = []\n",
    "            WnB.append(new_weights)\n",
    "            WnB.append(new_bias)\n",
    "    \n",
    "            VGG_3d_model.layers[layers_conv[i]].set_weights(WnB)\n",
    "\n",
    "    del pretrained_model, w, WnB, new_weights, new_bias, w3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b73eef-388d-4077-81f8-6eb93c39f318",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "732562b4-13a5-447d-8802-6be04933fcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionmatrix_multiclass(y_test,pred):\n",
    "    cm = confusion_matrix(y_test, (np.rint(preds)).astype(int) )\n",
    "    group_names = ['True baseline','False Baseline','False Baseline',   \n",
    "                   'False week 1','Truec','False Week 1',\n",
    "                  'False week 7','False week 7','True week 7']\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                    cm.flatten()]\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                         np.ndarray.flatten(cm/(np.sum(cm,axis=1).reshape(3,1)))]\n",
    "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "              zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(3,3)\n",
    "    sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', xticklabels = ['Baseline','Week 1','Week 7'] ,yticklabels = ['Baseline','Week 1','Week 7'])\n",
    "    plt.show()\n",
    "\n",
    "def confusionmatrix(y_test,preds):\n",
    "    #Construct the Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    group_names = ['True Naive','False Naive','False CPH','True CPH']\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                    cm.flatten()]\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                         np.ndarray.flatten(cm/(np.sum(cm,axis=1).reshape(2,1)))]\n",
    "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "              zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', xticklabels = ['MALE','FEMALE'] ,yticklabels = ['MALE','FEMALE'])\n",
    "    plt.show()\n",
    "    return sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', xticklabels = ['MALE','FEMALE'] ,yticklabels = ['MALE','FEMALE'])\n",
    "    \n",
    "def confusionmatrix_binary(y_test, preds):\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    group_names = ['True baseline','False baseline','False Week 1','True Week 1']\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                    cm.flatten()]\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                         np.ndarray.flatten(cm/(np.sum(cm,axis=1).reshape(2,1)))]\n",
    "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "              zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', xticklabels = ['MALE','FEMALE'] ,yticklabels = ['MALE','FEMALE'])\n",
    "    plt.show()\n",
    "\n",
    "def ROC(probs,y_test): #binary\n",
    "    #Classification Area under curve\n",
    "     warnings.filterwarnings('ignore')\n",
    "             \n",
    "     auc = roc_auc_score(y_test, probs)\n",
    "     print('AUC - Test Set: %.2f%%' % (auc*100))\n",
    "    \n",
    "     # calculate roc curve\n",
    "     fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "     # plot no skill\n",
    "     plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "     # plot the roc curve for the model\n",
    "     plt.plot(fpr, tpr, marker='.')\n",
    "     plt.xlabel('False positive rate')\n",
    "     plt.ylabel('Sensitivity/ Recall')\n",
    "     # show the plot\n",
    "     plt.show()\n",
    "    \n",
    "     probs = (np.rint(probs)).astype(int)   \n",
    "        \n",
    "     precision = precision_score(y_test, probs)\n",
    "     print('Precision: %f' % precision)\n",
    "     # recall: tp / (tp + fn)\n",
    "     recall = recall_score(y_test, probs)\n",
    "     print('Recall: %f' % recall)\n",
    "     # f1: tp / (tp + fp + fn)\n",
    "     f1 = f1_score(y_test, probs)\n",
    "     print('F1 score: %f' % f1)\n",
    "        \n",
    "def ROC_multiclass(model, y_test, n_class):\n",
    "    #y_test: array size (# of subjects, ) with classes \n",
    "    #pretrained model to be evaluated \n",
    "    \n",
    "    label_binarizer = LabelBinarizer().fit(y_test)\n",
    "    y_onehot_test = label_binarizer.transform(y_test)\n",
    "    y_onehot_test.shape  # (n_samples, n_classes)\n",
    "\n",
    "    y_score = model.predict(X_test) # y_score is onehot\n",
    "    \n",
    "    # store the fpr, tpr, and roc_auc for all averaging strategies\n",
    "    fpr, tpr, roc_auc = dict(), dict(), dict()\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_onehot_test.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    print(f\"Micro-averaged One-vs-Rest ROC AUC score:\\n{roc_auc['micro']:.2f}\")\n",
    "    \n",
    "    n_classes = n_class\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_onehot_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    fpr_grid = np.linspace(0.0, 1.0, 1000)\n",
    "\n",
    "    # Interpolate all ROC curves at these points\n",
    "    mean_tpr = np.zeros_like(fpr_grid)\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += np.interp(fpr_grid, fpr[i], tpr[i])  # linear interpolation\n",
    "\n",
    "    # Average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = fpr_grid\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    print(f\"Macro-averaged One-vs-Rest ROC AUC score:\\n{roc_auc['macro']:.2f}\")\n",
    "    \n",
    "    target_names = ['Naive','Week1','Week7']\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "    plt.plot(\n",
    "        fpr[\"micro\"],\n",
    "        tpr[\"micro\"],\n",
    "        label=f\"micro-average ROC curve (AUC = {roc_auc['micro']:.2f})\",\n",
    "        color=\"deeppink\",\n",
    "        linestyle=\":\",\n",
    "        linewidth=4,\n",
    "    )\n",
    "\n",
    "    plt.plot(\n",
    "        fpr[\"macro\"],\n",
    "        tpr[\"macro\"],\n",
    "        label=f\"macro-average ROC curve (AUC = {roc_auc['macro']:.2f})\",\n",
    "        color=\"navy\",\n",
    "        linestyle=\":\",\n",
    "        linewidth=4,\n",
    "    )\n",
    "\n",
    "    colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
    "    for class_id, color in zip(range(n_classes), colors):\n",
    "        RocCurveDisplay.from_predictions(\n",
    "            y_onehot_test[:, class_id],\n",
    "            y_score[:, class_id],\n",
    "            name=f\"ROC curve for {target_names[class_id]}\",\n",
    "            color=color,\n",
    "            ax=ax,\n",
    "            plot_chance_level=(class_id == 2),\n",
    "        )\n",
    "\n",
    "    _ = ax.set(\n",
    "        xlabel=\"False Positive Rate\",\n",
    "        ylabel=\"True Positive Rate\",\n",
    "        title=\"Extension of Receiver Operating Characteristic\\nto One-vs-Rest multiclass\",\n",
    "    )\n",
    "    \n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(histories):\n",
    "    c = ['b','g','r','c','m','y','k','w']\n",
    "    ltr = ['fold 1(train)','fold 2(train)','fold 3(train)','fold 4(train)','fold 5(train)']\n",
    "    lts = ['fold 1(val)','fold 2(val)','fold 3(val)','fold 4(val)','fold 5(val)']\n",
    "    for i in range(len(histories)):\n",
    "        # plot loss\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.title('Cross Entropy Loss')\n",
    "        plt.plot(histories[i].history['loss'], color=c[i], label=ltr[i], linestyle=\"-\")\n",
    "        plt.plot(histories[i].history['val_loss'], color=c[i], label=lts[i], linestyle=\"--\")\n",
    "        # plot accuracy\n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.title('Classification Accuracy')\n",
    "        plt.plot(histories[i].history['Accuracy'], color=c[i], label=ltr[i], linestyle=\"-\")\n",
    "        plt.plot(histories[i].history['val_Accuracy'], color=c[i], label=lts[i], linestyle=\"--\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# summarize model performance\n",
    "def summarize_performance(scores):\n",
    "    # print summary\n",
    "    print('Accuracy: mean=%.3f std=%.3f, n=%d' % (np.mean(scores)*100, np.std(scores)*100, len(scores)))\n",
    "    # box and whisker plots of results\n",
    "    plt.boxplot(scores)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08627ebe-a7e5-4c2c-a81f-5c3fd1f67025",
   "metadata": {},
   "source": [
    "# Just brain. Female. Naive vs CPH\n",
    "1) Naive (CPH_BL)\n",
    "2) CPH (CPH_W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31333e60-218e-4b1a-bd56-598d92c0dc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "female = [49,50,51,52,65,66,77,78,79,80,81,82,83]\n",
    "#female = [49,50,51,52,65,66]\n",
    "#female=[49,50,51,52,65,66,77,78,79]\n",
    "y_female = np.ones(len(female))\n",
    "\n",
    "subjects = np.array(female)\n",
    "labels = np.array(list(y_female))\n",
    "sessions = [1,2]\n",
    "MRI_type = \"func\"\n",
    "functional_type = \"rest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b11c966a-ca55-4ed6-a631-775f18290343",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: a01067716 (a01067716-tecnol-gico-de-monterrey) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5861269-6b1d-4a43-a0cd-abc4f3adbad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Bootstrapping Run 1/1 ===\n",
      "Run # 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.0s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\wandb\\run-20251010_164823-luz3ugwm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/a01067716-tecnol-gico-de-monterrey/FEMALE_Naive_vs_CPH%28BLvsW7%29/runs/luz3ugwm' target=\"_blank\">valiant-night-69</a></strong> to <a href='https://wandb.ai/a01067716-tecnol-gico-de-monterrey/FEMALE_Naive_vs_CPH%28BLvsW7%29' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/a01067716-tecnol-gico-de-monterrey/FEMALE_Naive_vs_CPH%28BLvsW7%29' target=\"_blank\">https://wandb.ai/a01067716-tecnol-gico-de-monterrey/FEMALE_Naive_vs_CPH%28BLvsW7%29</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/a01067716-tecnol-gico-de-monterrey/FEMALE_Naive_vs_CPH%28BLvsW7%29/runs/luz3ugwm' target=\"_blank\">https://wandb.ai/a01067716-tecnol-gico-de-monterrey/FEMALE_Naive_vs_CPH%28BLvsW7%29/runs/luz3ugwm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub train:\n",
      "['F:/rabies/preprocess_batch-002_rest/bold_datasink/commonspace_bold/_scan_info_subject_id081.session01_split_name_sub-081_ses-01_desc-o_T2w/_run_None/sub-081_ses-01_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-002_rest/bold_datasink/commonspace_bold/_scan_info_subject_id077.session01_split_name_sub-077_ses-01_desc-o_T2w/_run_None/sub-077_ses-01_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-001_rest/bold_datasink/commonspace_bold/_scan_info_subject_id052.session01_split_name_sub-052_ses-01_desc-o_T2w/_run_None/sub-052_ses-01_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-002_rest/bold_datasink/commonspace_bold/_scan_info_subject_id081.session02_split_name_sub-081_ses-02_desc-o_T2w/_run_None/sub-081_ses-02_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-002_rest/bold_datasink/commonspace_bold/_scan_info_subject_id077.session02_split_name_sub-077_ses-02_desc-o_T2w/_run_None/sub-077_ses-02_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-001_rest/bold_datasink/commonspace_bold/_scan_info_subject_id052.session02_split_name_sub-052_ses-02_desc-o_T2w/_run_None/sub-052_ses-02_task-rest_desc-oa_bold_autobox_combined.nii.gz']\n",
      "sub test:\n",
      "['F:/rabies/preprocess_batch-002_rest/bold_datasink/commonspace_bold/_scan_info_subject_id077.session01_split_name_sub-077_ses-01_desc-o_T2w/_run_None/sub-077_ses-01_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-001_rest/bold_datasink/commonspace_bold/_scan_info_subject_id065.session01_split_name_sub-065_ses-01_desc-o_T2w/_run_None/sub-065_ses-01_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-002_rest/bold_datasink/commonspace_bold/_scan_info_subject_id081.session01_split_name_sub-081_ses-01_desc-o_T2w/_run_None/sub-081_ses-01_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-002_rest/bold_datasink/commonspace_bold/_scan_info_subject_id077.session02_split_name_sub-077_ses-02_desc-o_T2w/_run_None/sub-077_ses-02_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-001_rest/bold_datasink/commonspace_bold/_scan_info_subject_id065.session02_split_name_sub-065_ses-02_desc-o_T2w/_run_None/sub-065_ses-02_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-002_rest/bold_datasink/commonspace_bold/_scan_info_subject_id081.session02_split_name_sub-081_ses-02_desc-o_T2w/_run_None/sub-081_ses-02_task-rest_desc-oa_bold_autobox_combined.nii.gz']\n",
      "sub val:\n",
      "['F:/rabies/preprocess_batch-002_rest/bold_datasink/commonspace_bold/_scan_info_subject_id077.session01_split_name_sub-077_ses-01_desc-o_T2w/_run_None/sub-077_ses-01_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-002_rest/bold_datasink/commonspace_bold/_scan_info_subject_id078.session01_split_name_sub-078_ses-01_desc-o_T2w/_run_None/sub-078_ses-01_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-002_rest/bold_datasink/commonspace_bold/_scan_info_subject_id077.session02_split_name_sub-077_ses-02_desc-o_T2w/_run_None/sub-077_ses-02_task-rest_desc-oa_bold_autobox_combined.nii.gz'\n",
      " 'F:/rabies/preprocess_batch-002_rest/bold_datasink/commonspace_bold/_scan_info_subject_id078.session02_split_name_sub-078_ses-02_desc-o_T2w/_run_None/sub-078_ses-02_task-rest_desc-oa_bold_autobox_combined.nii.gz']\n",
      "# sesiones Train 6\n",
      "# sesiones Test 6\n",
      "# sesiones Val 4\n",
      "Starting VGG 16 3D-----------------------------------------------------\n",
      "entra al 3\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING WandbCallback is deprecated and will be removed in a future release. Please use the WandbMetricsLogger, WandbModelCheckpoint, and WandbEvalCallback callbacks instead. See https://docs.wandb.ai/guides/integrations/keras for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "114/114 [==============================] - ETA: 0s - loss: 64.8479 - Accuracy: 0.5178 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\valiant-night-69\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\valiant-night-69\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1254s 11s/step - loss: 64.8479 - Accuracy: 0.5178 - val_loss: 62.6440 - val_Accuracy: 0.5000 - combine_metric: 0.0080\n",
      "Epoch 2/10\n",
      "114/114 [==============================] - ETA: 0s - loss: 60.4350 - Accuracy: 0.5345 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\valiant-night-69\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\valiant-night-69\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1336s 12s/step - loss: 60.4350 - Accuracy: 0.5345 - val_loss: 58.2345 - val_Accuracy: 0.5018 - combine_metric: 0.0086\n",
      "Epoch 3/10\n",
      "114/114 [==============================] - ETA: 0s - loss: 56.1997 - Accuracy: 0.6301 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\valiant-night-69\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\valiant-night-69\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1304s 11s/step - loss: 56.1997 - Accuracy: 0.6301 - val_loss: 54.2470 - val_Accuracy: 0.7500 - combine_metric: 0.0138\n",
      "Epoch 4/10\n",
      "114/114 [==============================] - ETA: 0s - loss: 52.5569 - Accuracy: 0.7658 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\valiant-night-69\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\valiant-night-69\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1399s 12s/step - loss: 52.5569 - Accuracy: 0.7658 - val_loss: 50.9880 - val_Accuracy: 0.7316 - combine_metric: 0.0143\n",
      "Epoch 5/10\n",
      "114/114 [==============================] - 1378s 12s/step - loss: 49.2485 - Accuracy: 0.8971 - val_loss: 48.0376 - val_Accuracy: 0.5000 - combine_metric: 0.0104\n",
      "Epoch 6/10\n",
      "114/114 [==============================] - ETA: 0s - loss: 46.2111 - Accuracy: 0.9705 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\valiant-night-69\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\valiant-night-69\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1301s 11s/step - loss: 46.2111 - Accuracy: 0.9705 - val_loss: 44.8812 - val_Accuracy: 0.8680 - combine_metric: 0.0193\n",
      "Epoch 7/10\n",
      "114/114 [==============================] - ETA: 0s - loss: 43.3794 - Accuracy: 0.9877 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\valiant-night-69\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\valiant-night-69\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1280s 11s/step - loss: 43.3794 - Accuracy: 0.9877 - val_loss: 42.1251 - val_Accuracy: 0.8496 - combine_metric: 0.0202\n",
      "Epoch 8/10\n",
      "114/114 [==============================] - ETA: 0s - loss: 40.6985 - Accuracy: 0.9918 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\valiant-night-69\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\PC-EIAD209\\Desktop\\AnaKei\\NIPD-AI\\valiant-night-69\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1271s 11s/step - loss: 40.6985 - Accuracy: 0.9918 - val_loss: 39.5208 - val_Accuracy: 0.9311 - combine_metric: 0.0236\n",
      "Epoch 9/10\n",
      "114/114 [==============================] - 1365s 12s/step - loss: 38.1495 - Accuracy: 0.9968 - val_loss: 37.1204 - val_Accuracy: 0.7500 - combine_metric: 0.0202\n",
      "Epoch 10/10\n",
      "114/114 [==============================] - 1476s 13s/step - loss: 35.7403 - Accuracy: 0.9971 - val_loss: 34.7736 - val_Accuracy: 0.7500 - combine_metric: 0.0216\n",
      "Duration (CNN): 3:43:13.760878\n",
      "Evaluating best epoch\n",
      "114/114 [==============================] - 95s 829ms/step - loss: 39.5613 - Accuracy: 0.8325\n",
      "predicts CNN\n",
      "114/114 [==============================] - 92s 804ms/step\n",
      "mislabeled subjects:\n",
      " Counter({'F:/rabies/preprocess_batch-001_rest/bold_datasink/commonspace_bold/_scan_info_subject_id065.session02_split_name_sub-065_ses-02_desc-o_T2w/_run_None/sub-065_ses-02_task-rest_desc-oa_bold_autobox_combined.nii.gz': 570, 'F:/rabies/preprocess_batch-002_rest/bold_datasink/commonspace_bold/_scan_info_subject_id077.session02_split_name_sub-077_ses-02_desc-o_T2w/_run_None/sub-077_ses-02_task-rest_desc-oa_bold_autobox_combined.nii.gz': 3})\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'filter_heatmap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 197\u001b[0m\n\u001b[0;32m    193\u001b[0m resized_heatmap_naive \u001b[38;5;241m=\u001b[39m get_resized_heatmap(heatmap_naive, rabies_crop\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m    194\u001b[0m resized_heatmap_cph   \u001b[38;5;241m=\u001b[39m get_resized_heatmap(heatmap_cph, rabies_crop\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m--> 197\u001b[0m resized_heatmap_naive\u001b[38;5;241m=\u001b[39m (\u001b[43mfilter_heatmap\u001b[49m(resized_heatmap_naive, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m))\n\u001b[0;32m    198\u001b[0m resized_heatmap_cph\u001b[38;5;241m=\u001b[39m (filter_heatmap(resized_heatmap_cph, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m))\n\u001b[0;32m    200\u001b[0m \u001b[38;5;66;03m# Animaciones coronal\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filter_heatmap' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "n_bootstraps= 1 #2\n",
    "for boot in range(n_bootstraps): \n",
    "    print(f\"\\n=== Bootstrapping Run {boot+1}/{n_bootstraps} ===\")\n",
    "\n",
    "    # Resample subjects + labels con reemplazo\n",
    "    boot_subjects, boot_labels = resample(\n",
    "     subjects, labels, replace=True, random_state=42+boot\n",
    "    )\n",
    "\n",
    "    sub_trainval, sub_test, y_trainval, y_test = train_test_split(\n",
    "    boot_subjects, boot_labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=2, shuffle=True, random_state=1)\n",
    "\n",
    "    scores, histories = list(), list()\n",
    "    run = 1\n",
    "    for train_ix, val_ix in kfold.split(sub_trainval, y_trainval):\n",
    "        print(\"Run #\",run)\n",
    "\n",
    "        sub_train, sub_val = boot_subjects[train_ix], boot_subjects[val_ix]\n",
    "        y_train, y_val     = boot_labels[train_ix], boot_labels[val_ix]\n",
    "        \n",
    "        \n",
    "        # Set default values\n",
    "        config_defaults = {\n",
    "            \"batch\": 4,\n",
    "        }\n",
    "        \n",
    "        # Initialize wandb with a sample project name\n",
    "        wandb.init(project=\"FEMALE_Naive_vs_CPH(BLvsW7)\", notes=\"No pooling. New data augmentation. Z-scoring per batch. Batch = 4. 10 epoch. Just z-scoring and applying RandomFlip. All layers gradcam. lr = 1e-5\",\n",
    "                    config=config_defaults)\n",
    "\n",
    "        # Specify the other hyperparameters to the configuration.\n",
    "        wandb.config.epochs = 10 #10\n",
    "        wandb.config.sub_batch = 30\n",
    "        wandb.config.sub_batch_ts = 30\n",
    "        wandb.config.subjects = subjects\n",
    "        wandb.config.architecture_name = \"VGG16_3D\"\n",
    "        wandb.config.dataset_name = \"NAIVE vs CPH(CPH[Bl-W1])\"\n",
    "        wandb.config.CNN_blocks = 5\n",
    "        wandb.config.sessions = sessions\n",
    "        wandb.config.vols_per_session_tr = 570\n",
    "        wandb.config.vols_per_session_ts = 570\n",
    "        wandb.config.initial_learning_rate = 1e-5\n",
    "        #wandb.config.lr_decay_rate = 0.95\n",
    "        wandb.config.optimizer = \"Adam\"\n",
    "        \n",
    "        #\n",
    "        val_size = max(2, int(round(0.1 * len(train_ix))))\n",
    "    \n",
    "        sub_train, sub_val, y_train, y_val = train_test_split(\n",
    "            sub_trainval[train_ix], y_trainval[train_ix],\n",
    "            test_size=val_size,  # test_size se refiere a la validacion\n",
    "            random_state=42, stratify=y_trainval[train_ix]\n",
    "        )\n",
    "\n",
    "        sub_test, y_test = sub_test, y_test\n",
    "        #\n",
    "        \n",
    "        CPHclassTrain = FILES_and_LABELS(sub_train, sessions, MRI_type, functional_type)\n",
    "        CPHclassTest = FILES_and_LABELS(sub_test, sessions, MRI_type, functional_type)\n",
    "        CPHclassval = FILES_and_LABELS(sub_val, sessions, MRI_type, functional_type)\n",
    "            \n",
    "        X_train = CPHclassTrain.get_mask_and_bold()\n",
    "        X_test = CPHclassTest.get_mask_and_bold()\n",
    "        X_val = CPHclassval.get_mask_and_bold()\n",
    "\n",
    "        wandb.config.batch = 4\n",
    "\n",
    "        print(\"sub train:\")\n",
    "        print(np.array(X_train)[:,0])\n",
    "        print(\"sub test:\")\n",
    "        print(np.array(X_test)[:,0])\n",
    "        print(\"sub val:\")\n",
    "        print(np.array(X_val)[:,0])\n",
    "\n",
    "        print(\"# sesiones Train\",len(X_train))\n",
    "        print(\"# sesiones Test\",len(X_test))\n",
    "        print(\"# sesiones Val\",len(X_val))\n",
    "        \n",
    "        traingen = CustomDataGen(X_train, batch_size=wandb.config.batch, subbatch_size=wandb.config.sub_batch,\n",
    "                                    format = \"just_brain\", vols = wandb.config.vols_per_session_tr,\n",
    "                                    num_class = 2, classes = \"CPHvsNAIVEfemale\", augmentation = True)\n",
    "        traingen.on_epoch_end()\n",
    "        #Es necesario que la division entre X_test y batch_size tenga un modulo igual a 0. \n",
    "        #De otra manera el ultimo batch no lo utiliza al utilizar .predict\n",
    "        testgen  = CustomDataGen(X_test, batch_size=1,subbatch_size=wandb.config.sub_batch_ts,\n",
    "                                    format = \"just_brain\", vols= wandb.config.vols_per_session_ts,\n",
    "                                    num_class = 2, classes = \"CPHvsNAIVEfemale\",shuffle=False)\n",
    "        valgen  = CustomDataGen(X_val, batch_size=len(X_val),subbatch_size=30, format = \"just_brain\",vols=570, num_class = 2, classes = \"CPHvsNAIVEfemale\")\n",
    "        \n",
    "        #getting model 3D CNN\n",
    "        #callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, min_delta=0.0001)\n",
    "        print(\"Starting VGG 16 3D-----------------------------------------------------\")\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "        CNN = VGG16_3D(3)\n",
    "        set_pretrained_weigths(CNN)\n",
    "\n",
    "        \"\"\"\n",
    "        lr_schedule = ExponentialDecay(wandb.config.initial_learning_rate,\n",
    "                                        decay_steps=int((wandb.config.vols_per_session_tr/wandb.config.sub_batch)*len(X_train)),\n",
    "                                        decay_rate=wandb.config.lr_decay_rate, staircase=True)\n",
    "        \"\"\"\n",
    "        CNN.compile(loss=tf.nn.softmax_cross_entropy_with_logits, optimizer=tf.keras.optimizers.Adam(learning_rate=wandb.config.initial_learning_rate),\n",
    "                        metrics=[\"Accuracy\"])\n",
    "\n",
    "        checkpoint_filepath = os.getcwd()+\"/\"+wandb.run.name\n",
    "        #'/tmp/ckpt/MalevsFemale(CPH)_3D-VGG16_flips/'+wandb.run.name\n",
    "\n",
    "        acc_loss_rate = CombineCallback()\n",
    "        \n",
    "        model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, monitor='combine_metric', mode='max',\n",
    "                                                                save_best_only=True)\n",
    "        \n",
    "        if os.path.exists(checkpoint_filepath):\n",
    "            print(\"Loading previous weights from:\", checkpoint_filepath)\n",
    "            CNN.load_weights(checkpoint_filepath)\n",
    "        else:\n",
    "            print(\"No previous checkpoint found, starting fresh.\")\n",
    "\n",
    "        \n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        print(\"Training\")\n",
    "        \n",
    "        history = CNN.fit(traingen, epochs=wandb.config.epochs, validation_data = valgen, shuffle=True,\n",
    "                            callbacks=[WandbCallback(monitor='combine_metric',mode=\"max\",save_model=(False)),acc_loss_rate,model_checkpoint_callback])\n",
    "        \n",
    "        end_time = datetime.now()\n",
    "        print('Duration (CNN): {}'.format(end_time - start_time))\n",
    "\n",
    "        print(\"Evaluating best epoch\")\n",
    "        CNN.load_weights(checkpoint_filepath)\n",
    "        CNN.compile(loss=tf.nn.softmax_cross_entropy_with_logits, optimizer=tf.keras.optimizers.Adam(learning_rate=wandb.config.initial_learning_rate),\n",
    "                        metrics=[\"Accuracy\"])\n",
    "        _,acc = CNN.evaluate(testgen, verbose=1)\n",
    "\n",
    "        y_test=[]\n",
    "        x_vols = []\n",
    "        for i in range(int(len(X_test)*(wandb.config.vols_per_session_ts/wandb.config.sub_batch_ts))):\n",
    "            x,y = testgen[i]\n",
    "            y_test.extend(y)\n",
    "            x_vols.extend(x)\n",
    "        y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "        \n",
    "        print(\"predicts CNN\")\n",
    "        preds = tf.cast(tf.argmax(CNN.predict(testgen), axis=1), tf.int32)\n",
    "\n",
    "        #Wrong predicted subjects\n",
    "        wrong_labeled_subj = mislabeled_subj(y_test, preds, X_test, wandb.config.vols_per_session_ts)\n",
    "\n",
    "        print(\"mislabeled subjects:\\n\",wrong_labeled_subj)\n",
    "        \n",
    "        scores.append(acc)\n",
    "        histories.append(history)\n",
    "\n",
    "        #GradCam\n",
    "        #Naive\n",
    "        if not os.path.exists(os.getcwd()+\"/\"+wandb.run.name+\"/Naive\"): \n",
    "            # if the demo_folder directory is not present  \n",
    "            # then create it. \n",
    "            os.makedirs(os.getcwd()+\"/\"+wandb.run.name+\"/Naive\")\n",
    "        #CPH\n",
    "        if not os.path.exists(os.getcwd()+\"/\"+wandb.run.name+\"/CPH\"): \n",
    "            # if the demo_folder directory is not present  \n",
    "            # then create it. \n",
    "            os.makedirs(os.getcwd()+\"/\"+wandb.run.name+\"/CPH\")\n",
    "\n",
    "        all_layers = [layer.name for layer in reversed(CNN.layers) if len(layer.output_shape) == 5 and (layer.__class__.__name__ == 'ReLU' or isinstance(layer, tf.keras.layers.Conv3D))]\n",
    "        \n",
    "        index_naive = index_for_gradcam(0,y_test,preds)\n",
    "        index_cph = index_for_gradcam(1,y_test,preds)\n",
    "\n",
    "\n",
    "        if index_naive is None:\n",
    "            index_naive = 0\n",
    "\n",
    "            print(\"No se encontró ningún sujeto Naive correctamente clasificado\")\n",
    "            print(\"index_naive se pone en 0 SOLO para poder correr el GradCAM\")\n",
    "\n",
    "\n",
    "        if index_cph is None:\n",
    "            print(\"No se encontró ningún sujeto CPH correctamente clasificado\")\n",
    "            print(\"index_cph se pone en 0 SOLO para poder correr el GradCAM\")\n",
    "            index_cph = 0\n",
    "\n",
    "        \n",
    "        #if index_naive is not None and index_cph is not None:\n",
    "\n",
    "        rabies_crop= rabies_vol[3:45, 4:69, 7:36] #original 48,81,48 #cropped 42,65,29\n",
    "\n",
    "        # GradCAM por clase\n",
    "        heatmap_naive = make_gradcam_heatmap(np.expand_dims(x_vols[index_naive], axis=0), CNN, all_layers[0])\n",
    "        heatmap_cph   = make_gradcam_heatmap(np.expand_dims(x_vols[index_cph],   axis=0), CNN, all_layers[0])\n",
    "        \n",
    "\n",
    "        resized_heatmap_naive = get_resized_heatmap(heatmap_naive, rabies_crop.shape[0:3])\n",
    "        resized_heatmap_cph   = get_resized_heatmap(heatmap_cph, rabies_crop.shape[0:3])\n",
    "\n",
    "   \n",
    "        resized_heatmap_naive= (filter_heatmap(resized_heatmap_naive, threshold=0.6))\n",
    "        resized_heatmap_cph= (filter_heatmap(resized_heatmap_cph, threshold=0.6))\n",
    "      \n",
    "        # Animaciones coronal\n",
    "        gradcam_naive = create_animation(rabies_crop, 'Naive', heatmap=resized_heatmap_naive)\n",
    "        gradcam_cph   = create_animation(rabies_crop,   'CPH',   heatmap=resized_heatmap_cph)\n",
    "\n",
    "        Writer = animation.writers['ffmpeg']\n",
    "        writer = Writer(fps=15, metadata=dict(artist='Me'), bitrate=1800)\n",
    "\n",
    "        name_ani_naive = os.getcwd() + \"/\" + wandb.run.name + \"/Naive/GradCam_Naive(BlVsW1-CPH).mp4\"\n",
    "        gradcam_naive.save(name_ani_naive, writer=writer)\n",
    "\n",
    "        name_ani_CPH = os.getcwd() + \"/\" + wandb.run.name + \"/CPH/GradCam_CPH(BlVsW1-CPH).mp4\"\n",
    "        gradcam_cph.save(name_ani_CPH, writer=writer)\n",
    "\n",
    "        # GradCAM promedio de todas las capas convolucionales\n",
    "        print(\"GradCam All ConvLayers\")\n",
    "        all_layers_gradcam_naive = fuse_layers(all_layers, CNN, [x_vols[index_naive]], 0, emphasize=False)\n",
    "        all_layers_gradcam_cph   = fuse_layers(all_layers, CNN,[x_vols[index_cph]], 0,   emphasize=False)\n",
    "\n",
    "        all_layers_animation_naive = create_animation(rabies_crop, 'all_layers_gradcam_Naive', heatmap=all_layers_gradcam_naive)\n",
    "        all_layers_animation_cph   = create_animation(rabies_crop,   'all_layers_gradcam_CPH',   heatmap=all_layers_gradcam_cph)\n",
    "\n",
    "        name_all_naive = os.getcwd() + \"/\" + wandb.run.name + \"/Naive/all_layers_gradcam_Naive.mp4\"\n",
    "        all_layers_animation_naive.save(name_all_naive, writer=writer)\n",
    "\n",
    "        name_all_cph = os.getcwd() + \"/\" + wandb.run.name + \"/CPH/all_layers_gradcam_CPH.mp4\"\n",
    "        all_layers_animation_cph.save(name_all_cph, writer=writer)\n",
    "\n",
    "\n",
    "        print(\"Máximo valor del heatmap CPH:\", np.max(resized_heatmap_cph))\n",
    "        print(\"Máximo valor del heatmap Naive:\", np.max(resized_heatmap_naive))\n",
    "\n",
    "        # Guardar PNGs frame por frame\n",
    "\n",
    "        full_grad_cph=np.zeros_like(rabies_vol)\n",
    "        full_grad_naive=np.zeros_like(rabies_vol)\n",
    "        full_grad_cph[3:45, 4:69, 7:36] = resized_heatmap_cph\n",
    "        full_grad_naive[3:45, 4:69, 7:36] = resized_heatmap_naive   \n",
    "\n",
    "        #rabies_vol= np.mean(rabies_ref, axis=3) #48,81,48\n",
    "        for i in range(rabies_vol.shape[1]):\n",
    "            plt.imshow(cv2.resize(np.rot90(rabies_vol[:,i,:]), dsize=(126,87)), alpha=0.8, cmap='bone')\n",
    "            plt.imshow(cv2.resize(np.rot90(full_grad_cph[:,i,:]), dsize=(126,87)), alpha=0.4, cmap='Reds')\n",
    "            plt.axis('off')\n",
    "            plt.savefig(os.getcwd()+\"/\"+wandb.run.name+\"/CPH/\"+str(i)+\".png\")\n",
    "            plt.show()\n",
    "\n",
    "        for i in range(rabies_vol.shape[1]):\n",
    "            plt.imshow(cv2.resize(np.rot90(rabies_vol[:,i,:]), dsize=(126,87)), alpha=0.8, cmap='bone')\n",
    "            plt.imshow(cv2.resize(np.rot90(full_grad_naive[:,i,:]), dsize=(126,87)), alpha=0.4, cmap='Reds')\n",
    "            plt.axis('off')\n",
    "            plt.savefig(os.getcwd()+\"/\"+wandb.run.name+\"/Naive/\"+str(i)+\".png\")\n",
    "            plt.show()\n",
    "\n",
    "        # Guardar arrays GradCAM\n",
    "        np.save(os.getcwd()+\"/\"+wandb.run.name+\"/CPH/Array_GradCam-CPH\", resized_heatmap_cph)\n",
    "        np.save(os.getcwd()+\"/\"+wandb.run.name+\"/Naive/Array_GradCam-Naive\", resized_heatmap_naive)\n",
    "\n",
    "        print(\"CM CNN\")\n",
    "        cm = confusionmatrix(y_test, preds)\n",
    "\n",
    "        # Log completo en Weights & Biases\n",
    "        wandb.log({\n",
    "            'test_acc': float(acc),\n",
    "            'time_running': '{}'.format(end_time - start_time),\n",
    "            'confution_matrix': wandb.Image(cm),\n",
    "            'mislabeled_subj': wrong_labeled_subj,\n",
    "            'GradCam_Naive-coronal': wandb.Video(name_ani_naive),\n",
    "            'GradCam-CPH-coronal': wandb.Video(name_ani_CPH),\n",
    "            'GradCam_Naive_all-layers': wandb.Video(name_all_naive),\n",
    "            'GradCam-CPH_all-layers': wandb.Video(name_all_cph),\n",
    "            'GradCam-per_frames-Naive': wandb.Image(grad_cam_per_frames(rabies_crop, resized_heatmap_naive, threshold=0.3)),\n",
    "            'GradCam-per_frames-CPH': wandb.Image(grad_cam_per_frames(rabies_crop, resized_heatmap_cph, threshold=0.3))\n",
    "        })\n",
    "\n",
    "\n",
    "        run = run + 1\n",
    "            \n",
    "    print(\"histories and scores from VGG 16 M2D\") \n",
    "    summarize_diagnostics(histories)\n",
    "    summarize_performance(scores)\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c28ae67f-97ec-4369-8cff-104825d88e6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/gdaalumno/OneDrive - Instituto Tecnologico y de Estudios Superiores de Monterrey/PainClassifier/Transfer Learning/VGG 16/FEMALE_Naive_vs_CPH(BLvsW1)/restful-disco-20/Naive/Array_GradCam-Naive.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m path3_male \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/gdaalumno/OneDrive - Instituto Tecnologico y de Estudios Superiores de Monterrey/PainClassifier/Transfer Learning/VGG 16/FEMALE_Naive_vs_CPH(BLvsW1)/wandering-surf-22/Naive/Array_GradCam-Naive.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m path4_male \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/gdaalumno/OneDrive - Instituto Tecnologico y de Estudios Superiores de Monterrey/PainClassifier/Transfer Learning/VGG 16/FEMALE_Naive_vs_CPH(BLvsW1)/amber-brook-23/Naive/Array_GradCam-Naive.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 6\u001b[0m cam1 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath1_male\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m cam2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(path2_male)\n\u001b[0;32m      8\u001b[0m cam3 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(path3_male)\n",
      "File \u001b[1;32mc:\\Users\\PC-EIAD209\\.conda\\envs\\nipd\\lib\\site-packages\\numpy\\lib\\npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/gdaalumno/OneDrive - Instituto Tecnologico y de Estudios Superiores de Monterrey/PainClassifier/Transfer Learning/VGG 16/FEMALE_Naive_vs_CPH(BLvsW1)/restful-disco-20/Naive/Array_GradCam-Naive.npy'"
     ]
    }
   ],
   "source": [
    "path1_male = \"C:/Users/gdaalumno/OneDrive - Instituto Tecnologico y de Estudios Superiores de Monterrey/PainClassifier/Transfer Learning/VGG 16/FEMALE_Naive_vs_CPH(BLvsW1)/restful-disco-20/Naive/Array_GradCam-Naive.npy\"\n",
    "path2_male = \"C:/Users/gdaalumno/OneDrive - Instituto Tecnologico y de Estudios Superiores de Monterrey/PainClassifier/Transfer Learning/VGG 16/FEMALE_Naive_vs_CPH(BLvsW1)/dazzling-dawn-21/Naive/Array_GradCam-Naive.npy\"\n",
    "path3_male = \"C:/Users/gdaalumno/OneDrive - Instituto Tecnologico y de Estudios Superiores de Monterrey/PainClassifier/Transfer Learning/VGG 16/FEMALE_Naive_vs_CPH(BLvsW1)/wandering-surf-22/Naive/Array_GradCam-Naive.npy\"\n",
    "path4_male = \"C:/Users/gdaalumno/OneDrive - Instituto Tecnologico y de Estudios Superiores de Monterrey/PainClassifier/Transfer Learning/VGG 16/FEMALE_Naive_vs_CPH(BLvsW1)/amber-brook-23/Naive/Array_GradCam-Naive.npy\"\n",
    "\n",
    "cam1 = np.load(path1_male)\n",
    "cam2 = np.load(path2_male)\n",
    "cam3 = np.load(path3_male)\n",
    "cam4 = np.load(path4_male)\n",
    "\n",
    "avgcam = np.mean(np.array([cam1,cam2,cam3,cam4]),axis=0)\n",
    "\n",
    "print(\"max\",avgcam.max())\n",
    "print(\"min\",avgcam.min())\n",
    "\n",
    "MRI_type = \"func\"\n",
    "functional_type = \"rest\"\n",
    "CPHclassTrain = FILES_and_LABELS([82], [1], MRI_type, functional_type)\n",
    "\n",
    "X_train = CPHclassTrain.get_mask_and_bold()\n",
    "traingen = CustomDataGen(X_train, batch_size=1, subbatch_size=30,\n",
    "                                 format = \"just_brain\", vols = 570,\n",
    "                                 num_class = 2, classes = \"sex\")\n",
    "\n",
    "x,y = traingen[0]\n",
    "\n",
    "grad_cam_per_frames(x[25],avgcam,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bdcfb2-c8c1-4736-9c95-ee024a993ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1_male = \"C:/Users/gdaalumno/OneDrive - Instituto Tecnologico y de Estudios Superiores de Monterrey/PainClassifier/Transfer Learning/VGG 16/FEMALE_Naive_vs_CPH(BLvsW1)/restful-disco-20/CPH/Array_GradCam-CPH.npy\"\n",
    "path2_male = \"C:/Users/gdaalumno/OneDrive - Instituto Tecnologico y de Estudios Superiores de Monterrey/PainClassifier/Transfer Learning/VGG 16/FEMALE_Naive_vs_CPH(BLvsW1)/dazzling-dawn-21/CPH/Array_GradCam-CPH.npy\"\n",
    "path3_male = \"C:/Users/gdaalumno/OneDrive - Instituto Tecnologico y de Estudios Superiores de Monterrey/PainClassifier/Transfer Learning/VGG 16/FEMALE_Naive_vs_CPH(BLvsW1)/wandering-surf-22/CPH/Array_GradCam-CPH.npy\"\n",
    "path4_male = \"C:/Users/gdaalumno/OneDrive - Instituto Tecnologico y de Estudios Superiores de Monterrey/PainClassifier/Transfer Learning/VGG 16/FEMALE_Naive_vs_CPH(BLvsW1)/amber-brook-23/CPH/Array_GradCam-CPH.npy\"\n",
    "\n",
    "cam1 = np.load(path1_male)\n",
    "cam2 = np.load(path2_male)\n",
    "cam3 = np.load(path3_male)\n",
    "cam4 = np.load(path4_male)\n",
    "\n",
    "avgcam = np.mean(np.array([cam1,cam2,cam3,cam4]),axis=0)\n",
    "\n",
    "print(\"max\",avgcam.max())\n",
    "print(\"min\",avgcam.min())\n",
    "\n",
    "MRI_type = \"func\"\n",
    "functional_type = \"rest\"\n",
    "CPHclassTrain = FILES_and_LABELS([82], [2], MRI_type, functional_type)\n",
    "\n",
    "X_train = CPHclassTrain.get_mask_and_bold()\n",
    "traingen = CustomDataGen(X_train, batch_size=1, subbatch_size=30,\n",
    "                                 format = \"just_brain\", vols = 570,\n",
    "                                 num_class = 2, classes = \"sex\")\n",
    "\n",
    "x,y = traingen[0]\n",
    "\n",
    "grad_cam_per_frames(x[25],avgcam,0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nipd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
